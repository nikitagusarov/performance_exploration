###################
# Simulation (MCMC)
###################

https://link.springer.com/article/10.2165/00003088-200140010-00002

https://ieeexplore.ieee.org/abstract/document/6147858

https://www.sciencedirect.com/science/article/abs/pii/S1755534517302002

https://books.google.fr/books?hl=fr&lr=&id=X01ZDwAAQBAJ&oi=fnd&pg=PP1&dq=introduction+simulation+data&ots=ebIGlrTXke&sig=EDeLzeyWdUa9PjIpkLUyJHnYj70&redir_esc=y#v=onepage&q=introduction%20simulation%20data&f=false

https://books.google.fr/books?hl=fr&lr=&id=ZXL6AQAAQBAJ&oi=fnd&pg=PP1&dq=introduction+simulation+data&ots=uPXnvX9EY6&sig=78cXLwdw-xOmowN779nxD7_o8e0&redir_esc=y#v=onepage&q=introduction%20simulation%20data&f=false

https://ieeexplore.ieee.org/abstract/document/5679166
https://orsociety.tandfonline.com/doi/abs/10.1057/jos.2012.20#.XqGLD8gzZcY

# https://eml.berkeley.edu/books/choice2.html (K. Train, 2009, "Discrete Choice Methods with Simulation" handbook)
@book{train2009dc,
  title={Discrete choice methods with simulation},
  author={Train, Kenneth E},
  year={2009},
  publisher={Cambridge university press}
}



####################
# Synthetic datasets 
####################

@article{albuquerque2011ds, 
    author={G. {Albuquerque} and T. {Lowe} and M. {Magnor}}, 
    journal={IEEE Transactions on Visualization and Computer Graphics}, 
    title={Synthetic Generation of High-Dimensional Datasets}, 
    year={2011}, 
    volume={17}, 
    number={12}, 
    pages={2317-2324},
    url={https://ieeexplore.ieee.org/abstract/document/6064998}
}

@article{garrow2010gs,
    author={Garrow, Laurie A.; Bodea, Tudor D.; Lee, Misuk},
    year={2010},
    title={Generation of synthetic datasets for discrete choice analysis},
    journal={Transportation},
    pages={183--202},
    volume={37},
    issue={2},
    abstract={Despite the widespread use of synthetic data in discrete choice analysis, little is known about how the methodology used to generate synthetic datasets influences the properties of parameter estimates and the validity of results based on these estimates. That is, there are two potential sources of biases when using synthetic discrete choice data: (1) bias due to the method used to generate the dataset; and, (2) bias due to parameter estimation. The primary objective of this study is to examine bias due to the underlying data generation method. This study compares three methods for generating synthetic datasets and uses design of experiments and analysis of variance methods to investigate the ability to recover estimates for “true” logsum parameters for nested logit models. The method that uses nested logit probabilities to generate the chosen alternative results in unbiased parameter estimates. The method that is based on Gumbel error component approximations reveals that while the error components themselves are unbiased, subtle empirical identification problems can arise when these error components are combined with synthetically generated utility functions. The method that is based on normal error component approximations reveals that all logsum coefficients are biased upwards; the bias dramatically increases for those nests that have a low choice frequency and is most pronounced for those nests with high correlations among alternatives. Based on the results of the analysis, several recommendations for the generation of synthetic datasets for discrete choice analyses are provided.},
    ibsn={1572-9435},
    url={https://doi.org/10.1007/s11116-009-9228-6},
    doi={10.1007/s11116-009-9228-6}
}

@inproceedings{vasilomanolakis2016ds, 
    author={E. {Vasilomanolakis} and C. G. {Cordero} and N. {Milanov} and M. {Mühlhäuser}}, 
    booktitle={NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium}, 
    title={Towards the creation of synthetic, yet realistic, intrusion detection datasets}, 
    year={2016}, 
    volume={}, 
    number={}, 
    pages={1209-1214},
    url={https://ieeexplore.ieee.org/abstract/document/7502989}
}

@article{gan2017sd,
    author = "Guojun Gan and Emiliano A. Valdez",
    title = "Valuation of large variable annuity portfolios: Monte Carlo simulation and synthetic datasets",
    journal = "Dependence Modeling",
    year = "2017",
    publisher = "De Gruyter",
    address = "Berlin, Boston",
    volume = "5",
    number = "1",
    pages = "354 - 374",
    url = "https://www.degruyter.com/view/journals/demo/5/1/article-p354.xml"
} 

@inproceedings{kar2019ms,
    author = {Kar, Amlan and Prakash, Aayush and Liu, Ming-Yu and Cameracci, Eric and Yuan, Justin and Rusiniak, Matt and Acuna, David and Torralba, Antonio and Fidler, Sanja},
    title = {Meta-Sim: Learning to Generate Synthetic Datasets},
    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
    month = {October},
    year = {2019},
    url = {http://openaccess.thecvf.com/content_ICCV_2019/html/Kar_Meta-Sim_Learning_to_Generate_Synthetic_Datasets_ICCV_2019_paper.html}
}

@article{charest2011dp, 
    title={How Can We Analyze Differentially-Private Synthetic Datasets?}, 
    volume={2}, 
    url={https://journalprivacyconfidentiality.org/index.php/jpc/article/view/589}, 
    DOI={10.29012/jpc.v2i2.589}, 
    abstractNote={Synthetic datasets generated within the multiple imputation framework are now commonly used by statistical agencies to protect the confidentiality of their respondents. More recently, researchers have also proposed techniques to generate synthetic datasets which offer the formal guarantee of differential privacy. While combining rules were derived for the first type of synthetic datasets, little has been said on the analysis of differentially-private synthetic datasets generated with multiple imputations. In this paper, we show that we can not use the usual combining rules to analyze synthetic datasets which have been generated to achieve differential privacy. We consider specifically the case of generating synthetic count data with the beta-binomial synthetizer, and illustrate our discussion with simulation results. We also propose as a simple alternative a Bayesian model which models explicitly the mechanism for synthetic data generation.}, 
    number={2}, 
    journal={Journal of Privacy and Confidentiality}, 
    author={Charest, Anne-Sophie}, 
    year={2011}, 
    month={Apr.}
} # Synthetic datasets and legislation (as was mentionned on 21/04)

@article{chiou2007sim,
    title = "Masking identification of discrete choice models under simulation methods",
    journal = "Journal of Econometrics",
    volume = "141",
    number = "2",
    pages = "683 - 703",
    year = "2007",
    issn = "0304-4076",
    doi = "https://doi.org/10.1016/j.jeconom.2006.10.012",
    url = "http://www.sciencedirect.com/science/article/pii/S0304407606002119",
    author = "Lesley Chiou and Joan L. Walker",
    keywords = "Simulation methods, Discrete choice, Identification",
    abstract = "We present examples based on actual and synthetic datasets to illustrate how simulation methods can mask identification problems in the estimation of discrete choice models such as mixed logit. Simulation methods approximate an integral (without a closed form) by taking draws from the underlying distribution of the random variable of integration. Our examples reveal how a low number of draws can generate estimates that appear identified, but in fact, are either not theoretically identified by the model or not empirically identified by the data. For the particular case of maximum simulated likelihood estimation, we investigate the underlying source of the problem by focusing on the shape of the simulated log-likelihood function under different conditions."
}

@article{drechsler2011sd_J,
    title = "An empirical evaluation of easily implemented, nonparametric methods for generating synthetic datasets",
    journal = "Computational Statistics & Data Analysis",
    volume = "55",
    number = "12",
    pages = "3232 - 3243",
    year = "2011",
    issn = "0167-9473",
    doi = "https://doi.org/10.1016/j.csda.2011.06.006",
    url = "http://www.sciencedirect.com/science/article/pii/S0167947311002076",
    author = "Jörg Drechsler and Jerome P. Reiter",
    keywords = "Census, Confidentiality, Disclosure, Imputation, Microdata, Synthetic",
    abstract = "When intense redaction is needed to protect the confidentiality of data subjects’ identities and sensitive attributes, statistical agencies can use synthetic data approaches. To create synthetic data, the agency replaces identifying or sensitive values with draws from statistical models estimated from the confidential data. Many agencies are reluctant to implement this idea because (i) the quality of the generated data depends strongly on the quality of the underlying models, and (ii) developing effective synthesis models can be a labor-intensive and difficult task. Recently, there have been suggestions that agencies use nonparametric methods from the machine learning literature to generate synthetic data. These methods can estimate non-linear relationships that might otherwise be missed and can be run with minimal tuning, thus considerably reducing burdens on the agency. Four synthesizers based on machine learning algorithms–classification and regression trees, bagging, random forests, and support vector machines–are evaluated in terms of their potential to preserve analytical validity while reducing disclosure risks. The evaluation is based on a repeated sampling simulation with a subset of the 2002 Uganda census public use sample data. The simulation suggests that synthesizers based on regression trees can result in synthetic datasets that provide reliable estimates and low disclosure risks, and that these synthesizers can be implemented easily by statistical agencies."
}