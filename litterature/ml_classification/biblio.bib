#####################
# Techniques overview
#####################

@article{kotsiantis2006tr,
    author = {Kotsiantis, Sotiris and Zaharakis, I. and Pintelas, P.},
    year = {2006},
    month = {11},
    pages = {159-190},
    title = {Machine learning: A review of classification and combining techniques},
    volume = {26},
    journal = {Artificial Intelligence Review},
    doi = {10.1007/s10462-007-9052-3}
}

@article{baldi2000ar,
    author = {Baldi, Pierre and Brunak, SÃ¸ren and Chauvin, Yves and Andersen, Claus A. F. and Nielsen, Henrik},
    title = "{Assessing the accuracy of prediction algorithms for classification: an overview}",
    journal = {Bioinformatics},
    volume = {16},
    number = {5},
    pages = {412-424},
    year = {2000},
    month = {05},
    abstract = "{Also at the Department of Biological Sciences, University of California, Irvine, USA, to whom all correspondence should be     addressed.We provide a unified overview of methods that currently are widely used to assess the accuracy of prediction algorithms, from raw percentages, quadratic error measures and other distances, and correlation coefficients, and to information theoretic measures such as relative entropy and mutual information. We briefly discuss the advantages and disadvantages of each approach. For classification tasks, we derive new learning algorithms for the design of prediction systems by directly optimising the correlation coefficient. We observe and prove several results relating sensitivity and specificity of optimal systems. While the principles are general, we illustrate the applicability on specific problems such as protein secondary structure and signal peptide prediction. Contact: pfbaldi@ics.uci.edu}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/16.5.412},
    url = {https://doi.org/10.1093/bioinformatics/16.5.412},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/16/5/412/476945/160412.pdf}
}

@article{tsoumakas2007cm,
    title = {Multi-Label Classification: An Overview},
    author = {Tsoumakas, Grigorios and Katakis, Ioannis},
    year = {2007},
    journal = {International Journal of Data Warehousing and Mining (IJDWM)},
    volume = {3},
    number = {3},
    pages = {1-13},
    abstract = {Multi-label classification methods are increasingly required by modern applications, such as protein function classification, music categorization, and semantic scene classification. This article introduces the task of multi-label classification, organizes the sparse related literature into a structured presentation and performs comparative experimental results of certain multilabel classification methods. It also contributes the definition of concepts for the quantification of the multi-label nature of a data set.},
    url = {https://EconPapers.repec.org/RePEc:igg:jdwm00:v:3:y:2007:i:3:p:1-13}
}

@article{ayodele2010tml,
    title={Types of machine learning algorithms},
    author={Ayodele, Taiwo Oladipupo},
    journal={New advances in machine learning},
    pages={19--48},
    year={2010},
    publisher={InTech}
}

@article{vijayakumar2019pa,
    author = {Ranjith Vijayakumar and Mike W.-L. Cheung},
    title ={Assessing Replicability of Machine Learning Results: An Introduction to Methods on Predictive Accuracy in Social Sciences},
    journal = {Social Science Computer Review},
    volume = {34},
    number = {1},
    pages = {0894439319888445},
    year = {2019},
    doi = {10.1177/0894439319888445},
    URL = {https://doi.org/10.1177/0894439319888445},
    eprint = {https://doi.org/10.1177/0894439319888445},
    abstract = { Machine learning methods have become very popular in diverse fields due to their focus on predictive accuracy, but little work has been conducted on how to assess the replicability of their findings. We introduce and adapt replication methods advocated in psychology to the aims and procedural needs of machine learning research. In Study 1, we illustrate these methods with the use of an empirical data set, assessing the replication success of a predictive accuracy measure, namely, R 2 on the cross-validated and test sets of the samples. We introduce three replication aims. First, tests of inconsistency examine whether single replications have successfully rejected the original study. Rejection will be supported if the 95\% confidence interval (CI) of R 2 difference estimates between replication and original does not contain zero. Second, tests of consistency help support claims of successful replication. We can decide apriori on a region of equivalence, where population values of the difference estimates are considered equivalent for substantive reasons. The 90\% CI of a different estimate lying fully within this region supports replication. Third, we show how to combine replications to construct meta-analytic intervals for better precision of predictive accuracy measures. In Study 2, R 2 is reduced from the original in a subset of replication studies to examine the ability of the replication procedures to distinguish true replications from nonreplications. We find that when combining studies sampled from same population to form meta-analytic intervals, random-effects methods perform best for cross-validated measures while fixed-effects methods work best for test measures. Among machine learning methods, regression was comparable to many complex methods, while support vector machine performed most reliably across a variety of scenarios. Social scientists who use machine learning to model empirical data can use these methods to enhance the reliability of their findings. }
}

@article{molina2019soc,
    author = {Molina, Mario and Garip, Filiz},
    title = {Machine Learning for Sociology},
    journal = {Annual Review of Sociology},
    volume = {45},
    number = {1},
    pages = {27-45},
    year = {2019},
    doi = {10.1146/annurev-soc-073117-041106},
    URL = {https://doi.org/10.1146/annurev-soc-073117-041106},
    eprint = {https://doi.org/10.1146/annurev-soc-073117-041106},
    abstract = {Machine learning is a field at the intersection of statistics and computer science that uses algorithms to extract information and knowledge from data. Its applications increasingly find their way into economics, political science, and sociology. We offer a brief introduction to this vast toolbox and illustrate its current uses in the social sciences, including distilling measures from new data sources, such as text and images; characterizing population heterogeneity; improving causal inference; and offering predictions to aid policy decisions and theory development. We argue that, in addition to serving similar purposes in sociology, machine learning tools can speak to long-standing questions on the limitations of the linear modeling framework, the criteria for evaluating empirical findings, transparency around the context of discovery, and the epistemological core of the discipline.}
}