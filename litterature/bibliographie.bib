##############
# Applications
##############

@article{penczynski2019com,
    author={Penczynski, Stefan P.},
    year={2019},
    title={Using machine learning for communication classification},
    journal={Experimental Economics},
    pages={1002--1029},
    volume={22},
    issue={4},
    abstract={The present study explores the value of machine learning techniques in the classification of communication content in experiments. Previously human-coded datasets are used to both train and test algorithm-generated models that relate word counts to categories. For various games, the computer models of the classification are able to match out-of-sample the human classification to a considerable extent. The analysis raises hope that the substantial effort going into such studies can be reduced by using computer algorithms for classification. This would enable a quick and replicable analysis of large-scale datasets at reasonable costs and widen the applicability of such approaches. The paper gives an easily accessible technical introduction into the computational method.},
    url={https://doi.org/10.1007/s10683-018-09600-z},
    doi={10.1007/s10683-018-09600-z}
}

@article{hrnjic2019beh,
    title={Machine learning and behavioral economics for personalized choice architecture},
    author={Hrnjic, Emir and Tomczak, Nikodem},
    journal={arXiv preprint arXiv:1907.02100},
    year={2019}
}

@article{greene2011ru,
    author = {Hensher, David A. and Greene, William H. and Chorus, Caspar G.},
    title = {Random regret minimization or random utility maximization: an exploratory analysis in the context of automobile fuel choice},
    journal = {Journal of Advanced Transportation},
    volume = {47},
    number = {7},
    pages = {667-678},
    keywords = {random regret, random utility, automobile choice, stated choice experiment, elasticities},
    doi = {10.1002/atr.188},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/atr.188},
    eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/atr.188},
    abstract = {SUMMARY Interest in alternative behavioural paradigms to random utility maximization (RUM) has existed ever since the dominance of the RUM formulation. One alternative is known as random regret minimization (RRM), which suggests that when choosing between alternatives, decision makers aim to minimize anticipated regret. Although the idea of regret is not new, its incorporation into the same discrete choice framework of RUM is very recent. This paper is the first to apply the RRM-model framework to model choice amongst durable goods. Specifically, we estimate and compare the RRM and RUM models in a stated choice context of choosing amongst vehicles fuelled with petrol, diesel and hybrid (associated with specific levels of fuel efficiency and engine capacity). The RRM model is found to achieve a marginally better fit (using a non-nested test of differences) than its equally parsimonious RUM counterpart. As a second contribution, we derive a formulation for regret-based elasticities and compare utility-based and regret-based elasticities in the context of stated vehicle type choices. We find that in the context of our choice data, mean estimates of elasticities are different for many of the attributes and alternatives. Copyright © 2011 John Wiley \& Sons, Ltd.},
    year = {2013}
}

@article{hastie2002gam,
    title = "Generalized linear and generalized additive models in studies of species distributions: setting the scene",
    journal = "Ecological Modelling",
    volume = "157",
    number = "2",
    pages = "89 - 100",
    year = "2002",
    issn = "0304-3800",
    doi = "https://doi.org/10.1016/S0304-3800(02)00204-1",
    url = "http://www.sciencedirect.com/science/article/pii/S0304380002002041",
    author = "Antoine Guisan and Thomas C Edwards and Trevor Hastie",
    keywords = "Statistical modeling, Generalized linear model, Generalized additive model, Species distribution, Predictive modeling",
    abstract = "An important statistical development of the last 30 years has been the advance in regression analysis provided by generalized linear models (GLMs) and generalized additive models (GAMs). Here we introduce a series of papers prepared within the framework of an international workshop entitled: Advances in GLMs/GAMs modeling: from species distribution to environmental management, held in Riederalp, Switzerland, 6–11 August 2001.We first discuss some general uses of statistical models in ecology, as well as provide a short review of several key examples of the use of GLMs and GAMs in ecological modeling efforts. We next present an overview of GLMs and GAMs, and discuss some of their related statistics used for predictor selection, model diagnostics, and evaluation. Included is a discussion of several new approaches applicable to GLMs and GAMs, such as ridge regression, an alternative to stepwise selection of predictors, and methods for the identification of interactions by a combined use of regression trees and several other approaches. We close with an overview of the papers and how we feel they advance our understanding of their application to ecological modeling."
}

@article{coussement2010gam,
    title = "Improved marketing decision making in a customer churn prediction context using generalized additive models",
    journal = "Expert Systems with Applications",
    volume = "37",
    number = "3",
    pages = "2132 - 2143",
    year = "2010",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2009.07.029",
    url = "http://www.sciencedirect.com/science/article/pii/S0957417409007325",
    author = "Kristof Coussement and Dries F. Benoit and Dirk Van den Poel",
    keywords = "Customer Relationship Management (CRM), Churn modeling, Marketing decision making, Generalized Additive Models (GAM)",
    abstract = "Nowadays, companies are investing in a well-considered CRM strategy. One of the cornerstones in CRM is customer churn prediction, where one tries to predict whether or not a customer will leave the company. This study focuses on how to better support marketing decision makers in identifying risky customers by using Generalized Additive Models (GAM). Compared to Logistic Regression, GAM relaxes the linearity constraint which allows for complex non-linear fits to the data. The contributions to the literature are three-fold: (i) it is shown that GAM is able to improve marketing decision making by better identifying risky customers; (ii) it is shown that GAM increases the interpretability of the churn model by visualizing the non-linear relationships with customer churn identifying a quasi-exponential, a U, an inverted U or a complex trend and (iii) marketing managers are able to significantly increase business value by applying GAM in this churn prediction context."
}

@article{demir2014comp,
    author = {Demir, Eren},
    title = {A Decision Support Tool for Predicting Patients at Risk of Readmission: A Comparison of Classification Trees, Logistic Regression, Generalized Additive Models, and Multivariate Adaptive Regression Splines},
    journal = {Decision Sciences},
    volume = {45},
    number = {5},
    pages = {849-880},
    keywords = {Risk of readmission, COPD, Predictive Analytics},
    doi = {10.1111/deci.12094},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/deci.12094},
    eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/deci.12094},
    abstract = {ABSTRACT The number of emergency (or unplanned) readmissions in the United Kingdom National Health Service (NHS) has been rising for many years. This trend, which is possibly related to poor patient care, places financial pressures on hospitals and on national healthcare budgets. As a result, clinicians and key decision makers (e.g., managers and commissioners) are interested in predicting patients at high risk of readmission. Logistic regression is the most popular method of predicting patient-specific probabilities. However, these studies have produced conflicting results with poor prediction accuracies. We compared the predictive accuracy of logistic regression with that of regression trees for predicting emergency readmissions within 45 days after been discharged from hospital. We also examined the predictive ability of two other types of data-driven models: generalized additive models (GAMs) and multivariate adaptive regression splines (MARS). We used data on 963 patients readmitted to hospitals with chronic obstructive pulmonary disease and asthma. We used repeated split-sample validation: the data were divided into derivation and validation samples. Predictive models were estimated using the derivation sample and the predictive accuracy of the resultant model was assessed using a number of performance measures, such as area under the receiver operating characteristic (ROC) curve in the validation sample. This process was repeated 1,000 times—the initial data set was divided into derivation and validation samples 1,000 times, and the predictive accuracy of each method was assessed each time. The mean ROC curve area for the regression tree models in the 1,000 derivation samples was .928, while the mean ROC curve area of a logistic regression model was .924. Our study shows that logistic regression model and regression trees had performance comparable to that of more flexible, data-driven models such as GAMs and MARS. Given that the models have produced excellent predictive accuracies, this could be a valuable decision support tool for clinicians (healthcare managers, policy makers, etc.) for informed decision making in the management of diseases, which ultimately contributes to improved measures for hospital performance management.},
    year = {2014}
}

@article{wong2020gen,
    title = "A bi-partite generative model framework for analyzing and simulating large scale multiple discrete-continuous travel behaviour data",
    journal = "Transportation Research Part C: Emerging Technologies",
    volume = "110",
    pages = "247 - 268",
    year = "2020",
    issn = "0968-090X",
    doi = "https://doi.org/10.1016/j.trc.2019.11.022",
    url = "http://www.sciencedirect.com/science/article/pii/S0968090X19300841",
    author = "Melvin Wong and Bilal Farooq",
    keywords = "Generative modelling, Entropy, Variational Bayesian inference, Machine learning, Travel behaviour modelling",
    abstract = "The emergence of data-driven demand analysis has led to the increased use of generative modelling to learn the probabilistic dependencies between random variables. Although their apparent use has mostly been limited to image recognition and classification in recent years, generative machine learning algorithms can be a powerful tool for travel behaviour research by replicating travel behaviour by the underlying properties of data structures. In this paper, we examine the use of generative machine learning approach for analyzing multiple discrete-continuous (MDC) travel behaviour data. We provide a plausible perspective of how we can exploit the use of machine learning techniques to interpret the underlying heterogeneities in the data. We show that generative models are conceptually similar to the choice selection behaviour process through information entropy and variational Bayesian inference. Without loss of generality, we consider a restricted Boltzmann machine (RBM) based algorithm with multiple discrete-continuous layers, formulated as a variational Bayesian inference optimization problem. We systematically describe the proposed machine learning algorithm and develop a process of analyzing travel behaviour data from a generative learning perspective. We show parameter stability from model analysis and simulation tests on an open dataset with multiple discrete-continuous dimensions from a data size of 293,330 observations. For interpretability, we derive the conditional probabilities, elasticities and perform statistical analysis on the latent variables. We show that our model can generate statistically similar data distributions for travel forecasting and prediction and performs better than purely discriminative methods in validation. Our results indicate that latent constructs in generative models can accurately represent the joint distribution consistently on MDC data."
}

@article{baayen2017gam,
    title = "The cave of shadows: Addressing the human factor with generalized additive mixed models",
    journal = "Journal of Memory and Language",
    volume = "94",
    pages = "206 - 234",
    year = "2017",
    issn = "0749-596X",
    doi = "https://doi.org/10.1016/j.jml.2016.11.006",
    url = "http://www.sciencedirect.com/science/article/pii/S0749596X16302467",
    author = "Harald Baayen and Shravan Vasishth and Reinhold Kliegl and Douglas Bates",
    keywords = "Generalized additive mixed models, Within-experiment adaptation, Autocorrelation, Experimental time series, Confirmatory versus exploratory data analysis, Model selection",
    abstract = "Generalized additive mixed models are introduced as an extension of the generalized linear mixed model which makes it possible to deal with temporal autocorrelational structure in experimental data. This autocorrelational structure is likely to be a consequence of learning, fatigue, or the ebb and flow of attention within an experiment (the ‘human factor’). Unlike molecules or plots of barley, subjects in psycholinguistic experiments are intelligent beings that depend for their survival on constant adaptation to their environment, including the environment of an experiment. Three data sets illustrate that the human factor may interact with predictors of interest, both factorial and metric. We also show that, especially within the framework of the generalized additive model, in the nonlinear world, fitting maximally complex models that take every possible contingency into account is ill-advised as a modeling strategy. Alternative modeling strategies are discussed for both confirmatory and exploratory data analysis."
}

@article{liu2019mvse,
    author = {Yan Liu and Tian Xie},
    title = {Machine learning versus econometrics: prediction of box office},
    journal = {Applied Economics Letters},
    volume = {26},
    number = {2},
    pages = {124-130},
    year  = {2019},
    publisher = {Routledge},
    doi = {10.1080/13504851.2018.1441499},
    URL = {https://doi.org/10.1080/13504851.2018.1441499},
    eprint = {https://doi.org/10.1080/13504851.2018.1441499},
    abstract = {In this note, we contrast prediction performance of nine econometric and machine learning methods, including a new hybrid method combining model averaging and machine learning, using data from the film industry and social media. The results suggest that machine learning methods have an advantage in addressing short-run noise, whereas traditional econometric methods are better at capturing long-run trend. In addition, once sample heterogeneity is controlled, the new hybrid method tends to strike a right balance in dealing with both noise and trend, leading to superior prediction efficiency. }
}





#####################
# Behavioural studies
#####################

@article{avineri2003su,
    author = {Erel Avineri and Joseph N. Prashker},
    title ={Sensitivity to Uncertainty: Need for a Paradigm Shift},
    journal = {Transportation Research Record},
    volume = {1854},
    number = {1},
    pages = {90-98},
    year = {2003},
    doi = {10.3141/1854-10},
    URL = {https://doi.org/10.3141/1854-10},
    eprint = {https://doi.org/10.3141/1854-10},
    abstract = { Existing common route choice models are based on random utility theory, which follows the maximum utility assumption. Recent intelligent transportation system applications have highlighted the need for better models of the behavioral processes involved in route choice decisions. Therefore, prediction of travelers' responses to uncertainty was analyzed. Route choice experiments were conducted to evaluate the effect of the feedback mechanism on decision making under uncertainty. The experimental results were compared with those from a model based on cumulative prospect theory and models based on learning approaches. It is shown that a traveler's sensitivity to travel time differences is lower when variances in travel times are higher. This better understanding of route choice behavior predicted by learning models may improve traffic predictions, as well as the design of traffic control mechanisms. }
}

@article{mccausland2013pd,
    title = "Prior distributions for random choice structures",
    journal = "Journal of Mathematical Psychology",
    volume = "57",
    number = "3",
    pages = "78 - 93",
    year = "2013",
    issn = "0022-2496",
    doi = "https://doi.org/10.1016/j.jmp.2013.05.001",
    url = "http://www.sciencedirect.com/science/article/pii/S0022249613000461",
    author = "William J. McCausland and A.A.J. Marley",
    keywords = "Bayesian inference, Choice axioms, Discrete choice, Probabilistic choice, Random utility",
    abstract = "We study various axioms of discrete probabilistic choice, measuring how restrictive they are, both alone and in the presence of other axioms, given a specific class of prior distributions over a complete collection of finite choice probabilities. We do this by using Monte Carlo simulation to compute, for a range of prior distributions, probabilities that various simple and compound axioms hold. For example, the probability of the triangle inequality is usually many orders of magnitude higher than the probability of random utility. While neither the triangle inequality nor weak stochastic transitivity imply the other, the conditional probability that one holds given the other holds is greater than the marginal probability, for all priors in the class we consider. The reciprocal of the prior probability that an axiom holds is an upper bound on the Bayes factor in favor of a restricted model, in which the axiom holds, against an unrestricted model. The relatively high prior probability of the triangle inequality limits the degree of support that data from a single decision maker can provide in its favor. The much lower probability of random utility implies that the Bayes factor in favor of it can be much higher, for suitable data."
}

@article{balbontin2019pcm,
    title = "How to better represent preferences in choice models: The contributions to preference heterogeneity attributable to the presence of process heterogeneity",
    journal = "Transportation Research Part B: Methodological",
    volume = "122",
    pages = "218 - 248",
    year = "2019",
    issn = "0191-2615",
    doi = "https://doi.org/10.1016/j.trb.2019.02.007",
    url = "http://www.sciencedirect.com/science/article/pii/S0191261518307859",
    author = "Camila Balbontin and David A. Hensher and Andrew T. Collins",
    abstract = "Discrete choice studies, with rare exception, commonly assume that agents act as if sources of observed utility are captured through a linear in parameters and additive in attributes (LPAA) form, with some interactions. A growing number of transport (and other) choice studies have investigated one or more alternative processing rules adopted by agents in arriving at a choice, raising interest in how best to represent the utility expressions in a joint process and outcome choice model. Given the popular and appealing random parameter treatment of LPAA in mixed logit as a way of identifying non-systematic preference heterogeneity in a sample, this paper considers the possibility that we might be able to interact specific process heuristics with LPAA to uncover sources of systematic preference heterogeneity hidden in the standard LPAA form, and hence establish a link between the LPAA form and candidate process heuristics, offering a way to embellish and hence clarify the contributions to preference heterogeneity attributable to the presence of process heterogeneity. Specifically, we are interested in the extent to which there is a systematic relationship between the simple LPAA form and the more complex (albeit behaviourally realistic) process heuristics emerging in the transport literature which we call conditioning by random process heterogeneity (CRPH). In this paper, in addition to LPAA, we consider two process heuristics - Value Learning, and Relative Advantage Maximisation - with an overlay to account for risk attitudes, perceptual conditioning, and overt experience. The findings, using two data sets, suggest that empirically there exists a significant attribute-specific relationship between preference heterogeneity identified through specific process heuristics and through the LPAA assumption."
}

@article{belgiawan2019cdm,
    author = {Prawira Fajarindra Belgiawan and Ilka Dubernet and Basil Schmid and Kay Axhausen},
    title = {Context-dependent models (CRRM, MuRRM, PRRM, RAM) versus a context-free model (MNL) in transportation studies: a comprehensive comparisons for Swiss and German SP and RP data sets},
    journal = {Transportmetrica A: Transport Science},
    volume = {15},
    number = {2},
    pages = {1487-1521},
    year  = {2019},
    publisher = {Taylor & Francis},
    doi = {10.1080/23249935.2019.1612968},
    URL = {https://doi.org/10.1080/23249935.2019.1612968},
    eprint = {https://doi.org/10.1080/23249935.2019.1612968}
}

@article {leong2015ram,
    title = "Contrasts of Relative Advantage Maximisation with Random Utility Maximisation and Regret Minimisation",
    journal = "Journal of Transport Economics and Policy (JTEP)",
    parent_itemid = "infobike://lse/jtep",
    publishercode ="lse",
    year = "2015",
    volume = "49",
    number = "1",
    date ="2015-01-01T00:00:00",
    pages = "167-186",
    itemtype = "ARTICLE",
    issn = "0022-5258",
    url = "https://www.ingentaconnect.com/content/lse/jtep/2015/00000049/00000001/art00010",
    author = "Leong, Waiyan and Hensher, David A.",
    abstract = "This paper discusses the theoretical properties and the empirical application of an improved version of the 'relative advantage maximising' (RAM) model. This model shares several desirable features of a set of models based on random regret minimisation (RRM), such as parsimony and choice set dependence. Although model fit differences are small, a preliminary comparison shows that the RAM model empirically outperforms the standard random utility maximisation (RUM) model, the RRM model, and a hybrid RUMRRM model in all eight data sets analysed. The paper concludes with a discussion of the marginal willingness to pay (WTP) measures derived from the RAM model.",
}

@techreport{brock2003mcsi,
    title = {Multinomial Choice with Social Interactions},
    author = {Brock, William and Durlauf, Steven},
    year = {2003},
    institution = {National Bureau of Economic Research, Inc},
    type = {NBER Technical Working Papers},
    number = {0288},
    abstract = {This paper develops a model of individual decisionmaking in the presence of social interactions when the number of available choices is finite. We show how a multinomial logit model framework may be used to model such decisions in a way that permits a tight integration of theory and econometrics. Conditions are given under which aggregate choice behavior in a population exhibits multiple self-consistent equilibria. An econometric version of the model is shown to be identified under relatively weka conditions. That analysis is extended to allow for general error distributions and some preliminary ways to account for the endogeneity of group memberships are developed.},
    url = {https://EconPapers.repec.org/RePEc:nbr:nberte:0288}
}

@article{pigozzi2016pai,
    TITLE = {{Preferences in Artificial Intelligence}},
    AUTHOR = {Pigozzi, Gabriella and Tsouki{\`a}s, Alexis and Viappiani, Paolo},
    URL = {https://hal.archives-ouvertes.fr/hal-01222363},
    JOURNAL = {{Annals of Mathematics and Artificial Intelligence}},
    PUBLISHER = {{Springer Verlag}},
    VOLUME = {77},
    NUMBER = {3-4},
    PAGES = {361-401},
    YEAR = {2016},
    DOI = {10.1007/s10472-015-9475-5},
    HAL_ID = {hal-01222363},
    HAL_VERSION = {v1},
}

@inproceedings{tsoukias2013ph,
    TITLE = {{Tutorial on preference handling}},
    AUTHOR = {Tsouki{\`a}s, Alexis and Viappiani, Paolo},
    URL = {https://hal.archives-ouvertes.fr/hal-01215237},
    BOOKTITLE = {{ACM Conference on Recommender System (RecSys)}},
    ADDRESS = {Hong Kong, China},
    PAGES = {497-498},
    YEAR = {2013},
    MONTH = Oct,
    DOI = {10.1145/2507157.2508065},
    HAL_ID = {hal-01215237},
    HAL_VERSION = {v1},
}

@inproceedings{sihem2009rs,
    author = {Abbassi, Zeinab and Amer-Yahia, Sihem and Lakshmanan, Laks V.S. and Vassilvitskii, Sergei and Yu, Cong},
    title = {Getting Recommender Systems to Think Outside the Box},
    year = {2009},
    isbn = {9781605584355},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1639714.1639769},
    doi = {10.1145/1639714.1639769},
    booktitle = {Proceedings of the Third ACM Conference on Recommender Systems},
    pages = {285–288},
    numpages = {4},
    keywords = {diversity, OTB, serendipity, recommendation, outside the box},
    location = {New York, New York, USA},
    series = {RecSys ’09}
}





####################################
# Papers proposition for application
####################################

@article{rose2008sce,
    title = "Designing efficient stated choice experiments in the presence of reference alternatives",
    journal = "Transportation Research Part B: Methodological",
    volume = "42",
    number = "4",
    pages = "395 - 406",
    year = "2008",
    issn = "0191-2615",
    doi = "https://doi.org/10.1016/j.trb.2007.09.002",
    url = "http://www.sciencedirect.com/science/article/pii/S0191261507000811",
    author = "John M. Rose and Michiel C.J. Bliemer and David A. Hensher and Andrew T. Collins",
    keywords = "Stated choice, Efficient experimental designs, D-efficiency, Orthogonal design, Reference alternatives",
    abstract = "This paper examines various design strategies that might be employed to construct statistically more efficient stated choice designs in the presence of a reference alternative in a choice set. Using data collected in Sydney in 2004 in the context of trading time and cost attributes associated with alternative tolled and non-tolled routes to drive a car to work, we contrast D-efficient designs (based on a number of ways of pivoting attribute levels around a reference alternative) with the more traditional orthogonal designs and conclude that D-efficiency design strategies produce significantly improved results, in a statistical sense of relative efficiency, than the more traditional orthogonal design. Furthermore, the increased use of computer aided personal survey instruments and internet-based surveys enables researchers to structure the experiments around the very specific experiences of each sampled respondent, adding relevance and comprehendability to the attribute levels being assessed in contrast to other averaging methods to construct reference alternatives."
}

@article{llerena2013rose,
    author = {Michaud, Celine and Llerena, Daniel and Joly, Iragael},
    title = "{Willingness to pay for environmental attributes of non-food agricultural products: a real choice experiment}",
    journal = {European Review of Agricultural Economics},
    volume = {40},
    number = {2},
    pages = {313-329},
    year = {2012},
    month = {07},
    abstract = "{This paper investigates consumers'willingness to pay a price premium for two environmental attributes of a non-food agricultural product. We study individual preferences for roses associated with an eco-label and a carbon footprint, using an economic experiment combining discrete choice questions and real economic incentives involving real purchases of roses against cash. The data are analysed with a mixed logit model and reveal significant premiums for both environmental attributes of the product.}",
    issn = {0165-1587},
    doi = {10.1093/erae/jbs025},
    url = {https://doi.org/10.1093/erae/jbs025},
    eprint = {https://academic.oup.com/erae/article-pdf/40/2/313/1205395/jbs025.pdf},
}





##################################################
# Model comparison mthods, assessing performance #
##################################################

@article{karlafti2011svsml,
    title = "Statistical methods versus neural networks in transportation research: Differences, similarities and some insights",
    journal = "Transportation Research Part C: Emerging Technologies",
    volume = "19",
    number = "3",
    pages = "387 - 399",
    year = "2011",
    issn = "0968-090X",
    doi = "https://doi.org/10.1016/j.trc.2010.10.004",
    url = "http://www.sciencedirect.com/science/article/pii/S0968090X10001610",
    author = "M.G. Karlaftis and E.I. Vlahogianni",
    keywords = "Statistical models, Neural networks, Transportation research",
    abstract = "In the field of transportation, data analysis is probably the most important and widely used research tool available. In the data analysis universe, there are two ; the first uses statistics as the tool of choice, while the second Computational Intelligence. Although the goal of both approaches is the same, the two have kept each other at arms work. In this paper, we discuss differences and similarities between these two approaches, we review relevant literature and attempt to provide a set of insights for selecting the appropriate approach."
}

@article{askin2013cp,
    title = "Comparing the Predictive and Classification Performances of Logistic Regression and Neural Networks: A Case Study on Timss 2011",
    journal = "Procedia - Social and Behavioral Sciences",
    volume = "106",
    pages = "667 - 676",
    year = "2013",
    note = "4th International Conference on New Horizons in Education",
    issn = "1877-0428",
    doi = "https://doi.org/10.1016/j.sbspro.2013.12.076",
    url = "http://www.sciencedirect.com/science/article/pii/S1877042813046910",
    author = "Oykum Esra Askin and Fulya Gokalp",
    keywords = "TIMSS 2011, neural networks, logistic regression",
    abstract = "Investigating effective factors on students’ achievement has wide application area in educational studies. Specially, Trends in International Mathematics and Science Study (TIMSS) allows researchers to determine correlates of mathematics and science achievement for different countries. In this study, the predictive and classification performances of logistic regression and neural networks are compared to identify the impact levels of variables on students’ mathematics achievement in Turkey. Age, gender and scales created by TIMSS team for 8th grade students (students like learning, value learning, confident in math, engaged in math, bullied at school, home educational resources), are selected as predictive variables. Model fitting statistics show that two methods give similar results in prediction and classification. In addition to model results, students’ confidence is found as the most effective factor to improve mathematics achievement."
}

@article{liu2011lr,
    author={Liu, Yuan Y.; Yang, Min; Ramsay, Malcolm; Li, Xiao S.; Coid, Jeremy W.},
    year={2011},
    date={2011/12/01},
    title={A Comparison of Logistic Regression, Classification and Regression Tree, and Neural Networks Models in Predicting Violent Re-Offending},
    journal={Journal of Quantitative Criminology},
    pages={547-573},
    volume={27},
    issue={4},
    abstract={Previous studies that have compared logistic regression (LR), classification and regression tree (CART), and neural networks (NNs) models for their predictive validity have shown inconsistent results in demonstrating superiority of any one model. The three models were tested in a prospective sample of 1225 UK male prisoners followed up for a mean of 3.31 years after release. Items in a widely-used risk assessment instrument (the Historical, Clinical, Risk Management-20, or HCR-20) were used as predictors and violent reconvictions as outcome. Multi-validation procedure was used to reduce sampling error in reporting the predictive accuracy. The low base rate was controlled by using different measures in the three models to minimize prediction error and achieve a more balanced classification. Overall accuracy of the three models varied between 0.59 and 0.67, with an overall AUC range of 0.65–0.72. Although the performance of NNs was slightly better than that of LR and CART models, it did not demonstrate a significant improvement.},
    ibsn={1573-7799},
    url={https://doi.org/10.1007/s10940-011-9137-7},
    doi={10.1007/s10940-011-9137-7}
}

@inproceedings{schulz2014predict,
    title={Predict choice: A comparison of 21 mathematical models},
    author={Schulz, Eric and Speekenbrink, Maarten and Shanks, David R},
    booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
    volume={36},
    number={36},
    year={2014}
}

@article{baogan2008ec,
    title = "Evaluation Criteria Based on Mutual Information for Classifications Including Rejected Class",
    journal = "Acta Automatica Sinica",
    volume = "34",
    number = "11",
    pages = "1396 - 1403",
    year = "2008",
    issn = "1874-1029",
    doi = "https://doi.org/10.1016/S1874-1029(08)60061-0",
    url = "http://www.sciencedirect.com/science/article/pii/S1874102908600610",
    author = "Bao-Gang HU and Yong WANG",
    keywords = "Entropy, mutual information, evaluation criteria, classification, confusion matrix, machine learning",
    abstract = "Different from the conventional evaluation criteria using performance measures, information theory based criteria present a unique beneficial feature in applications of machine learning. However, we are still far from possessing an in-depth understanding of the “entropy” type criteria, say, in relation to the conventional performance-based criteria. This paper studies generic classification problems, which include a rejected, or unknown, class. We present the basic formulas and schematic diagram of classification learning based on information theory. A closed-form equation is derived between the normalized mutual information and the augmented confusion matrix for the generic classification problems. Three theorems and one set of sensitivity equations are given for studying the relations between mutual information and conventional performance indices. We also present numerical examples and several discussions related to advantages and limitations of mutual information criteria in comparison with the conventional criteria."
}

@article{sokolova2009sa,
    title = "A systematic analysis of performance measures for classification tasks",
    journal = "Information Processing & Management",
    volume = "45",
    number = "4",
    pages = "427 - 437",
    year = "2009",
    issn = "0306-4573",
    doi = "https://doi.org/10.1016/j.ipm.2009.03.002",
    url = "http://www.sciencedirect.com/science/article/pii/S0306457309000259",
    author = "Marina Sokolova and Guy Lapalme",
    keywords = "Performance evaluation, Machine Learning, Text classification",
    abstract = "This paper presents a systematic analysis of twenty four performance measures used in the complete spectrum of Machine Learning classification tasks, i.e., binary, multi-class, multi-labelled, and hierarchical. For each classification task, the study relates a set of changes in a confusion matrix to specific characteristics of data. Then the analysis concentrates on the type of changes to a confusion matrix that do not change a measure, therefore, preserve a classifier’s evaluation (measure invariance). The result is the measure invariance taxonomy with respect to all relevant label distribution changes in a classification problem. This formal analysis is supported by examples of applications where invariance properties of measures lead to a more reliable evaluation of classifiers. Text classification supplements the discussion with several case studies."
}

@article{zhu2017es,
    title = "An evaluation study on text categorization using automatically generated labeled dataset",
    journal = "Neurocomputing",
    volume = "249",
    pages = "321 - 336",
    year = "2017",
    issn = "0925-2312",
    doi = "https://doi.org/10.1016/j.neucom.2016.04.072",
    url = "http://www.sciencedirect.com/science/article/pii/S0925231217305696",
    author = "Dengya Zhu and Kok Wai Wong",
    keywords = "Text mining, Text categorization, Machine learning, Evaluation, Feature selection, Benchmark collection",
    abstract = "Naïve Bayes, k-nearest neighbors, Adaboost, support vector machines and neural networks are five among others commonly used text classifiers. Evaluation of these classifiers involves a variety of factors to be considered including benchmark used, feature selections, parameter settings of algorithms, and the measurement criteria employed. Researchers have demonstrated that some algorithms outperform others on some corpus, however, inconsistency of human labeling and high dimensionality of feature spaces are two issues to be addressed in text categorization. This paper focuses on evaluating the five commonly used text classifiers by using an automatically generated text document collection which is labeled by a group of experts to alleviate subjectivity of human category assignments, and at the same time to examine the influence of the number of features on the performance of the algorithms."
}

@article{yangho2020cpa,
    title = "Avoid Oversimplifications in Machine Learning: Going beyond the Class-Prediction Accuracy",
    journal = "Patterns",
    volume = "1",
    number = "2",
    pages = "100025",
    year = "2020",
    issn = "2666-3899",
    doi = "https://doi.org/10.1016/j.patter.2020.100025",
    url = "http://www.sciencedirect.com/science/article/pii/S2666389920300258",
    author = "Sung Yang Ho and Limsoon Wong and Wilson Wen Bin Goh",
    keywords = "machine learning, data science, validation, artificial intelligence",
    abstract = "Class-prediction accuracy provides a quick but superficial way of determining classifier performance. It does not inform on the reproducibility of the findings or whether the selected or constructed features used are meaningful and specific. Furthermore, the class-prediction accuracy oversummarizes and does not inform on how training and learning have been accomplished: two classifiers providing the same performance in one validation can disagree on many future validations. It does not provide explainability in its decision-making process and is not objective, as its value is also affected by class proportions in the validation set. Despite these issues, this does not mean we should omit the class-prediction accuracy. Instead, it needs to be enriched with accompanying evidence and tests that supplement and contextualize the reported accuracy. This additional evidence serves as augmentations and can help us perform machine learning better while avoiding naive reliance on oversimplified metrics."
}

@article{andersson1999cpe,
    title = "Measure-based classifier performance evaluation",
    journal = "Pattern Recognition Letters",
    volume = "20",
    number = "11",
    pages = "1165 - 1173",
    year = "1999",
    issn = "0167-8655",
    doi = "https://doi.org/10.1016/S0167-8655(99)00084-7",
    url = "http://www.sciencedirect.com/science/article/pii/S0167865599000847",
    author = "Arne Andersson and Paul Davidsson and Johan Lindén",
    keywords = "Classifier performance evaluation, Cross-validation, Generalization",
    abstract = "The concept of measure functions for classifier performance is suggested. This concept provides an alternative way of selecting and evaluating learned classifiers, and it allows us to define the learning problem as a computational problem."
}

@article{zhou2020mrc,
    title = "An analysis on the relationship between uncertainty and misclassification rate of classifiers",
    journal = "Information Sciences",
    volume = "535",
    pages = "16 - 27",
    year = "2020",
    issn = "0020-0255",
    doi = "https://doi.org/10.1016/j.ins.2020.05.059",
    url = "http://www.sciencedirect.com/science/article/pii/S0020025520304461",
    author = "Xinlei Zhou and Xizhao Wang and Cong Hu and Ran Wang",
    keywords = "Uncertianty, Supervised learning, Classification problem, Misclassification rate, Statistical distribution",
    abstract = "This paper provides new insight into the analysis on the relationship between uncertainty and misclassification of a classifier. We formulate the relationship explicitly by taking entropy as a measurement of uncertainty and by analyzing the misclassification rate based on the membership degree difference. Focusing on binary classification problems, this study theoretically and experimentally validates that the misclassification rate will definitely be upgrading with the increase of uncertainty if two conditions are satisfied: (1) the distributions of two classes based on membership degree difference are unimodal, and (2) these two distributions attain peaks when the membership degree difference is less and larger than zero, respectively. This work aims to provide some practical guidelines for improving classifier performance through clearly expressing and understanding the relationship between uncertainty and misclassification of a classifier."
}

@article{armano2015cba,
    title = "A direct measure of discriminant and characteristic capability for classifier building and assessment",
    journal = "Information Sciences",
    volume = "325",
    pages = "466 - 483",
    year = "2015",
    issn = "0020-0255",
    doi = "https://doi.org/10.1016/j.ins.2015.07.028",
    url = "http://www.sciencedirect.com/science/article/pii/S0020025515005241",
    author = "Giuliano Armano",
    keywords = "Classifier performance measures, Feature ranking/selection, Confusion matrices",
    abstract = "Performance measures are used in various stages of the process aimed at solving a classification problem. Unfortunately, most of these measures are in fact biased, meaning that they strictly depend on the class ratio – i.e. on the imbalance between negative and positive samples. After pointing to the source of bias for the best known measures, novel unbiased measures are defined which are able to capture the concepts of discriminant and characteristic capability. The combined use of these measures can give important information to researchers involved in machine learning or pattern recognition tasks, in particular for classifier performance assessment and feature selection."
}

@article{chen2012cvtt,
    title = "Classifier variability: Accounting for training and testing",
    journal = "Pattern Recognition",
    volume = "45",
    number = "7",
    pages = "2661 - 2671",
    year = "2012",
    issn = "0031-3203",
    doi = "https://doi.org/10.1016/j.patcog.2011.12.024",
    url = "http://www.sciencedirect.com/science/article/pii/S0031320312000180",
    author = "Weijie Chen and Brandon D. Gallas and Waleed A. Yousef",
    keywords = "Classifier evaluation, Training variability, Classifier stability, -statistics, ",
    abstract = "We categorize the statistical assessment of classifiers into three levels: assessing the classification performance and its testing variability conditional on a fixed training set, assessing the performance and its variability that accounts for both training and testing, and assessing the performance averaging over training sets and its variability that accounts for both training and testing. We derived analytical expressions for the variance of the estimated AUC and provide freely available software implemented with an efficient computation algorithm. Our approach can be applied to assess any classifier that has ordinal (continuous or discrete) outputs. Applications to simulated and real datasets are presented to illustrate our methods."
}

@article{tama2019ecct,
    title = "An empirical comparison of classification techniques for next event prediction using business process event logs",
    journal = "Expert Systems with Applications",
    volume = "129",
    pages = "233 - 245",
    year = "2019",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2019.04.016",
    url = "http://www.sciencedirect.com/science/article/pii/S0957417419302465",
    author = "Bayu Adhi Tama and Marco Comuzzi",
    keywords = "Process indicators, Classification algorithms, Significance test, Performance evaluation, Event log, Empirical benchmark",
    abstract = "Predictive analytics is an essential capability in business process management to forecast future status and performance of business processes. In this paper, we focus on one particular predictive monitoring task that is solved using classification techniques, i.e. predicting the next event in a case. Several different classifiers have been recently employed in the literature in this task. However, a quantitative benchmark of different classifiers is currently lacking. In this paper, we build such a benchmark by taking into account 20 classifiers from five families, i.e. trees, Bayesian, rule-based, neural and meta classifiers. We employ six real-world process event logs and consider two different sampling approaches, i.e. case and event-based sampling, and three different validation methods in order to acquire a comprehensive evaluation about the classifiers’ performance. According to our benchmark, the classifier most likely to be the overall superior performer is the credal decision tree (C-DT), followed by the other top-4 performers, i.e. random forest, decision tree, dagging ensemble, and nested dichotomies ensemble. We also provide a qualitative discussion of how features of an event log can affect the choice of best classifier."
}

@article{freitas2014ccm,
    author = {Freitas, Alex A.},
    title = {Comprehensible Classification Models: A Position Paper},
    year = {2014},
    issue_date = {June 2013},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {15},
    number = {1},
    issn = {1931-0145},
    url = {https://doi.org/10.1145/2594473.2594475},
    doi = {10.1145/2594473.2594475},
    journal = {SIGKDD Explor. Newsl.},
    month = mar,
    pages = {1–10},
    numpages = {10},
    keywords = {nearest neighbors, Bayesian network classifiers, monotonicity constraint, decision tree, decision table, rule induction}
}

@article{portugal2018mlrs,
    title = "The use of machine learning algorithms in recommender systems: A systematic review",
    journal = "Expert Systems with Applications",
    volume = "97",
    pages = "205 - 227",
    year = "2018",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2017.12.020",
    url = "http://www.sciencedirect.com/science/article/pii/S0957417417308333",
    author = "Ivens Portugal and Paulo Alencar and Donald Cowan",
    keywords = "Systematic review of the literature, Recommender systems, Machine learning, Machine learning algorithms, Application domains, Performance metrics",
    abstract = "Recommender systems use algorithms to provide users with product or service recommendations. Recently, these systems have been using machine learning algorithms from the field of artificial intelligence. However, choosing a suitable machine learning algorithm for a recommender system is difficult because of the number of algorithms described in the literature. Researchers and practitioners developing recommender systems are left with little information about the current approaches in algorithm usage. Moreover, the development of recommender systems using machine learning algorithms often faces problems and raises questions that must be resolved. This paper presents a systematic review of the literature that analyzes the use of machine learning algorithms in recommender systems and identifies new research opportunities. The goals of this study are to (i) identify trends in the use or research of machine learning algorithms in recommender systems; (ii) identify open questions in the use or research of machine learning algorithms; and (iii) assist new researchers to position new research activity in this domain appropriately. The results of this study identify existing classes of recommender systems, characterize adopted machine learning approaches, discuss the use of big data technologies, identify types of machine learning algorithms and their application domains, and analyzes both main and alternative performance metrics."
}

@article{hagenauer2017mlcmc,
    title = "A comparative study of machine learning classifiers for modeling travel mode choice",
    journal = "Expert Systems with Applications",
    volume = "78",
    pages = "273 - 282",
    year = "2017",
    issn = "0957-4174",
    doi = "https://doi.org/10.1016/j.eswa.2017.01.057",
    url = "http://www.sciencedirect.com/science/article/pii/S0957417417300738",
    author = "Julian Hagenauer and Marco Helbich",
    keywords = "Travel mode choice, Classification, Machine learning, The Netherlands",
    abstract = "The analysis of travel mode choice is an important task in transportation planning and policy making in order to understand and predict travel demands. While advances in machine learning have led to numerous powerful classifiers, their usefulness for modeling travel mode choice remains largely unexplored. Using extensive Dutch travel diary data from the years 2010 to 2012, enriched with variables on the built and natural environment as well as on weather conditions, this study compares the predictive performance of seven selected machine learning classifiers for travel mode choice analysis and makes recommendations for model selection. In addition, it addresses the importance of different variables and how they relate to different travel modes. The results show that random forest performs significantly better than any other of the investigated classifiers, including the commonly used multinomial logit model. While trip distance is found to be the most important variable, the importance of the other variables varies with classifiers and travel modes. The importance of the meteorological variables is highest for support vector machine, while temperature is particularly important for predicting bicycle and public transport trips. The results suggest that the analysis of variable importance with respect to the different classifiers and travel modes is essential for a better understanding and effective modeling of people’s travel behavior."
}

@article {kubus2020ec,
    author = "Mariusz Kubus",
    title = "Evaluation of Resampling Methods in the Class Unbalance Problem",
    journal = "Econometrics",
    year = "2020",
    publisher = "Sciendo",
    address = "Berlin",
    volume = "24",
    number = "1",
    pages = "39 - 50",      
    url = "https://content.sciendo.com/view/journals/eada/24/1/article-p39.xml"
}

@inproceedings{drummond2006mles,
    title={Machine learning as an experimental science (revisited)},
    author={Drummond, Chris},
    booktitle={Proceedings of the Twenty-First National Conference on Artificial Intelligence: Workshop on Evaluation Methods for Machine Learning},
    pages={1--5},
    year={2006}
}

@inproceedings{costa2007rev,
    title={A review of performance evaluation measures for hierarchical classifiers},
    author={Costa, Eduardo and Lorena, Ana and Carvalho, ACPLF and Freitas, Alex},
    booktitle={Evaluation Methods for machine Learning II: papers from the AAAI-2007 Workshop},
    pages={1--6},
    year={2007}
}

@inproceedings{flach2019peml,
    title={Performance Evaluation in Machine Learning: The Good, the Bad, the Ugly, and the Way Forward},
    author={Flach, Peter},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    volume={33},
    pages={9808--9814},
    year={2019}
}








#######################
# Handbooks and manuals
#######################

@book{cascetta2009tr,
    title={Transportation systems analysis: models and applications},
    author={Cascetta, Ennio},
    volume={29},
    year={2009},
    publisher={Springer Science \& Business Media}
}

@book{hastie2009sl,
    title={The elements of statistical learning: data mining, inference, and prediction},
    author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
    year={2009},
    publisher={Springer Science \& Business Media}
}

@book{agresti2007cd,
    title={An Introduction to Categorical Data Analysis, Second Edition},
    year={2007},
    author={Agresti, Alan}
}

@book{agresti2013cd,
    author={Agresti, Alan},
    title={Categorical Data Analysis, Third Edition},
    year={2013}
}

@book{depalma2011tr,
    title={A handbook of transport economics},
    author={De Palma, Andr{\'e} and Lindsey, Robin and Quinet, Emile and Vickerman, Roger},
    year={2011},
    publisher={Edward Elgar Publishing}
}

@book{jebara2004ml,
    title={Machine learning: discriminative and generative},
    author={Jebara, Tony},
    year={2004},
    publisher={Springer Science \& Business Media}
} 

@book{drechsler2011sd,
    title={Synthetic datasets for statistical disclosure control: theory and implementation},
    author={Drechsler, J{\"o}rg},
    volume={201},
    year={2011},
    publisher={Springer Science \& Business Media},
    url={https://www.springer.com/gp/book/9781461403258#reviews}
}

@book{zielesny2011cf,
    title={From Curve Fitting to Machine Learning},
    author={Zielesny, Achim},
    volume={18},
    year={2011},
    publisher={Springer}
}

@book{denuit2019as1,
    title={Effective statistical learning methods for actuaries I: GLMs and Extentions},
    author={Denuit, Michel and Trufin, Julien},
    year={2019},
    publisher={Springer}
}

@book{denuit2019as3,
    title={Effective Statistical Learning Methods for Actuaries III: Neural networks and extentions},
    author={Denuit, Michel and Hainaut, Donatien},
    publisher={Springer},
    year={2019}
}

@book{japkowicz2011el, 
    place={Cambridge}, 
    title={Evaluating Learning Algorithms: A Classification Perspective}, 
    DOI={10.1017/CBO9780511921803}, 
    publisher={Cambridge University Press}, 
    author={Japkowicz, Nathalie and Shah, Mohak}, 
    year={2011}
}

@book{furnkranz2011p,
    author = {J. F\"urnkranz and E. H\"ullermeier},
    title = {Preference Learning},
    publisher = {Springer Verlag, Berlin},
    year = {2010}
}

@book{train2009dc,
    title={Discrete choice methods with simulation},
    author={Train, Kenneth E},
    year={2009},
    publisher={Cambridge university press}
}

@book{johannes2011,
    author = {J. F\"urnkranz and E. H\"ullermeier},
    title = {Preference Learning},
    publisher = {Springer Verlag, Berlin},
    year = {2010}
}

@misc{baltagi2008ec,
    title={Econometrics, 4th edition},
    author={Baltagi, Badi},
    year={2008},
    publisher={Berlin: Springer}
}








#####################
# Techniques overview
#####################

@article{kotsiantis2006tr,
    author = {Kotsiantis, Sotiris and Zaharakis, I. and Pintelas, P.},
    year = {2006},
    month = {11},
    pages = {159-190},
    title = {Machine learning: A review of classification and combining techniques},
    volume = {26},
    journal = {Artificial Intelligence Review},
    doi = {10.1007/s10462-007-9052-3}
}

@article{baldi2000ar,
    author = {Baldi, Pierre and Brunak, Søren and Chauvin, Yves and Andersen, Claus A. F. and Nielsen, Henrik},
    title = "{Assessing the accuracy of prediction algorithms for classification: an overview}",
    journal = {Bioinformatics},
    volume = {16},
    number = {5},
    pages = {412-424},
    year = {2000},
    month = {05},
    abstract = "{Also at the Department of Biological Sciences, University of California, Irvine, USA, to whom all correspondence should be     addressed.We provide a unified overview of methods that currently are widely used to assess the accuracy of prediction algorithms, from raw percentages, quadratic error measures and other distances, and correlation coefficients, and to information theoretic measures such as relative entropy and mutual information. We briefly discuss the advantages and disadvantages of each approach. For classification tasks, we derive new learning algorithms for the design of prediction systems by directly optimising the correlation coefficient. We observe and prove several results relating sensitivity and specificity of optimal systems. While the principles are general, we illustrate the applicability on specific problems such as protein secondary structure and signal peptide prediction. Contact: pfbaldi@ics.uci.edu}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/16.5.412},
    url = {https://doi.org/10.1093/bioinformatics/16.5.412},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/16/5/412/476945/160412.pdf}
}

@article{tsoumakas2007cm,
    title = {Multi-Label Classification: An Overview},
    author = {Tsoumakas, Grigorios and Katakis, Ioannis},
    year = {2007},
    journal = {International Journal of Data Warehousing and Mining (IJDWM)},
    volume = {3},
    number = {3},
    pages = {1-13},
    abstract = {Multi-label classification methods are increasingly required by modern applications, such as protein function classification, music categorization, and semantic scene classification. This article introduces the task of multi-label classification, organizes the sparse related literature into a structured presentation and performs comparative experimental results of certain multilabel classification methods. It also contributes the definition of concepts for the quantification of the multi-label nature of a data set.},
    url = {https://EconPapers.repec.org/RePEc:igg:jdwm00:v:3:y:2007:i:3:p:1-13}
}

@article{ayodele2010tml,
    title={Types of machine learning algorithms},
    author={Ayodele, Taiwo Oladipupo},
    journal={New advances in machine learning},
    pages={19--48},
    year={2010},
    publisher={InTech}
}

@article{vijayakumar2019pa,
    author = {Ranjith Vijayakumar and Mike W.-L. Cheung},
    title ={Assessing Replicability of Machine Learning Results: An Introduction to Methods on Predictive Accuracy in Social Sciences},
    journal = {Social Science Computer Review},
    volume = {34},
    number = {1},
    pages = {0894439319888445},
    year = {2019},
    doi = {10.1177/0894439319888445},
    URL = {https://doi.org/10.1177/0894439319888445},
    eprint = {https://doi.org/10.1177/0894439319888445},
    abstract = { Machine learning methods have become very popular in diverse fields due to their focus on predictive accuracy, but little work has been conducted on how to assess the replicability of their findings. We introduce and adapt replication methods advocated in psychology to the aims and procedural needs of machine learning research. In Study 1, we illustrate these methods with the use of an empirical data set, assessing the replication success of a predictive accuracy measure, namely, R 2 on the cross-validated and test sets of the samples. We introduce three replication aims. First, tests of inconsistency examine whether single replications have successfully rejected the original study. Rejection will be supported if the 95\% confidence interval (CI) of R 2 difference estimates between replication and original does not contain zero. Second, tests of consistency help support claims of successful replication. We can decide apriori on a region of equivalence, where population values of the difference estimates are considered equivalent for substantive reasons. The 90\% CI of a different estimate lying fully within this region supports replication. Third, we show how to combine replications to construct meta-analytic intervals for better precision of predictive accuracy measures. In Study 2, R 2 is reduced from the original in a subset of replication studies to examine the ability of the replication procedures to distinguish true replications from nonreplications. We find that when combining studies sampled from same population to form meta-analytic intervals, random-effects methods perform best for cross-validated measures while fixed-effects methods work best for test measures. Among machine learning methods, regression was comparable to many complex methods, while support vector machine performed most reliably across a variety of scenarios. Social scientists who use machine learning to model empirical data can use these methods to enhance the reliability of their findings. }
}

@article{molina2019soc,
    author = {Molina, Mario and Garip, Filiz},
    title = {Machine Learning for Sociology},
    journal = {Annual Review of Sociology},
    volume = {45},
    number = {1},
    pages = {27-45},
    year = {2019},
    doi = {10.1146/annurev-soc-073117-041106},
    URL = {https://doi.org/10.1146/annurev-soc-073117-041106},
    eprint = {https://doi.org/10.1146/annurev-soc-073117-041106},
    abstract = {Machine learning is a field at the intersection of statistics and computer science that uses algorithms to extract information and knowledge from data. Its applications increasingly find their way into economics, political science, and sociology. We offer a brief introduction to this vast toolbox and illustrate its current uses in the social sciences, including distilling measures from new data sources, such as text and images; characterizing population heterogeneity; improving causal inference; and offering predictions to aid policy decisions and theory development. We argue that, in addition to serving similar purposes in sociology, machine learning tools can speak to long-standing questions on the limitations of the linear modeling framework, the criteria for evaluating empirical findings, transparency around the context of discovery, and the epistemological core of the discipline.}
}





#############################################
# Machine learning and economics/econometrics
#############################################

@article{athey2019ml,
    author = {Athey, Susan and Imbens, Guido W.},
    title = {Machine Learning Methods That Economists Should Know About},
    journal = {Annual Review of Economics},
    volume = {11},
    number = {1},
    pages = {685-725},
    year = {2019},
    doi = {10.1146/annurev-economics-080217-053433},
    URL = {https://doi.org/10.1146/annurev-economics-080217-053433},
    eprint = {https://doi.org/10.1146/annurev-economics-080217-053433},
    abstract = {We discuss the relevance of the recent machine learning (ML) literature for economics and econometrics. First we discuss the differences in goals, methods, and settings between the ML literature and the traditional econometrics and statistics literatures. Then we discuss some specific methods from the ML literature that we view as important for empirical researchers in economics. These include supervised learning methods for regression and classification, unsupervised learning methods, and matrix completion methods. Finally, we highlight newly developed methods at the intersection of ML and econometrics that typically perform better than either off-the-shelf ML or more traditional econometric methods when applied to particular classes of problems, including causal inference for average treatment effects, optimal policy estimation, and estimation of the counterfactual effect of price changes in consumer choice models.}
}

@article{mullainathan2017ml,
    Author = {Mullainathan, Sendhil and Spiess, Jann},
    Title = {Machine Learning: An Applied Econometric Approach},
    Journal = {Journal of Economic Perspectives},
    Volume = {31},
    Number = {2},
    Year = {2017},
    Month = {May},
    Pages = {87-106},
    DOI = {10.1257/jep.31.2.87},
    URL = {http://www.aeaweb.org/articles?id=10.1257/jep.31.2.87}
}

@inbook{athey2018iml,
    Crossref = "agrawal2019nber",
    title = "The Impact of Machine Learning on Economics",
    author = "Susan Athey",
    BookTitle = "The Economics of Artificial Intelligence: An Agenda",
    Publisher = "University of Chicago Press",
    pages = "507-547",
    year = "2018",
    month = "January",
    URL = "http://www.nber.org/chapters/c14009",
}
@book{agrawal2019nber,
    title = "The Economics of Artificial Intelligence: An Agenda",
    author = "Ajay Agrawal and Joshua Gans and Avi Goldfarb",
    institution = "National Bureau of Economic Research",
    type = "Book",
    publisher = "University of Chicago Press",
    year = "2019",
    doi = {https://doi.org/10.7208/chicago/9780226613475.001.0001},
    URL = "http://www.nber.org/books/agra-1",
}

@article{varian2014bd,
    Author = {Varian, Hal R.},
    Title = {Big Data: New Tricks for Econometrics},
    Journal = {Journal of Economic Perspectives},
    Volume = {28},
    Number = {2},
    Year = {2014},
    Month = {May},
    Pages = {3-28},
    DOI = {10.1257/jep.28.2.3},
    URL = {http://www.aeaweb.org/articles?id=10.1257/jep.28.2.3}
}

@article{breiman2001stat,
    title={Statistical modeling: The two cultures (with comments and a rejoinder by the author)},
    author={Breiman, Leo and others},
    journal={Statistical science},
    volume={16},
    number={3},
    pages={199--231},
    year={2001},
    publisher={Institute of Mathematical Statistics}
}

@article{donoho2017ds,
    title={50 years of data science},
    author={Donoho, David},
    journal={Journal of Computational and Graphical Statistics},
    volume={26},
    number={4},
    pages={745--766},
    year={2017},
    publisher={Taylor \& Francis}
}

@article{chen2013rac,
    title={Regression and causation: a critical examination of six econometrics textbooks},
    author={Chen, Bryant and Pearl, Judea},
    journal={Real-World Economics Review, Issue},
    number={65},
    pages={2--20},
    year={2013}
}





######################################
# Neural networks and marginal effects
######################################

https://ideas.repec.org/p/ags/aaea15/205649.html

https://www.sciencedirect.com/science/article/abs/pii/S0031320306002081

https://arxiv.org/abs/1711.09784

https://arxiv.org/abs/1806.01933

https://www.emerald.com/insight/content/doi/10.1108/MF-04-2018-0156/full/html

https://krex.k-state.edu/dspace/handle/2097/35802

https://aisel.aisnet.org/icis2019/data_science/data_science/26/

https://pdfs.semanticscholar.org/5cc5/2c482db27510f9fca080a3982814d4139660.pdf
# ???

http://papers.nips.cc/paper/8003-towards-robust-interpretability-with-self-explaining-neural-networks
@incollection{alvarez2018senn,
    title = {Towards Robust Interpretability with Self-Explaining Neural Networks},
    author = {Alvarez Melis, David and Jaakkola, Tommi},
    booktitle = {Advances in Neural Information Processing Systems 31},
    editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
    pages = {7775--7784},
    year = {2018},
    publisher = {Curran Associates, Inc.},
    url = {http://papers.nips.cc/paper/8003-towards-robust-interpretability-with-self-explaining-neural-networks.pdf}
}

@article{farrell2018deep,
    title={Deep neural networks for estimation and inference: Application to causal effects and other semiparametric estimands},
    author={Farrell, Max H and Liang, Tengyuan and Misra, Sanjog},
    journal={arXiv preprint arXiv:1809.09953},
    year={2018}
}

@misc{wang2018deep,
    title={Deep Neural Networks for Choice Analysis: A Statistical Learning Theory Perspective},
    author={Shenhao Wang and Qingyi Wang and Nate Bailey and Jinhua Zhao},
    year={2018},
    eprint={1810.10465},
    archivePrefix={arXiv},
    primaryClass={econ.GN}
}

@misc{gao2016matrix,
    title={Matrix Neural Networks},
    author={Junbin Gao and Yi Guo and Zhiyong Wang},
    year={2016},
    eprint={1601.03805},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{doshivelez2017iml,
    title={Towards A Rigorous Science of Interpretable Machine Learning},
    author={Finale Doshi-Velez and Been Kim},
    year={2017},
    eprint={1702.08608},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{pulugurta2013aimc,
    title = "Use of Artificial Intelligence for Mode Choice Analysis and Comparison with Traditional Multinomial Logit Model",
    journal = "Procedia - Social and Behavioral Sciences",
    volume = "104",
    pages = "583 - 592",
    year = "2013",
    note = "2nd Conference of Transportation Research Group of India (2nd CTRG)",
    issn = "1877-0428",
    doi = "https://doi.org/10.1016/j.sbspro.2013.11.152",
    url = "http://www.sciencedirect.com/science/article/pii/S1877042813045436",
    author = "Sarada Pulugurta and Ashutosh Arun and Madhu Errampalli",
    keywords = "Mode Choice, Fuzzy Logic, Multinomial Logit, genfis, MATLAB, LIMDEP",
    abstract = "Travel Demand Forecasting, an essential tool to predict the future demand, is a four stage procedure which involves trip generation, trip distribution, mode choice and traffic assignment, out of which, mode choice analysis plays vital role as it deals with predicting mode used by the travelers to reach their destination. Multinomial Logit (MNL) model is a traditional model adopted for mode choice analysis which has major limitation that the input variables need to have crisp values and hence should be measured accurately which consumes lot of time and resources. Moreover, decision of trip maker for choosing a mode involves human approximations which are not precisely captured by MNL model. This can be overcome by using artificial intelligence techniques like fuzzy logic for modeling mode choice behavior. Fuzzy logic try to harness the human knowledge which is often guided by approximations by accepting input values in linguistic terms. The fuzzy rule base comprises several IF-THEN rules which closely resemble human knowledge and decision-making. In this study, it was thus proposed to apply the concept of fuzzy logic for modeling mode choice and compare the results with traditional MNL model. For this purpose, a total of 5822 samples were collected in Port Blair city, India and data pertaining to input variables viz. in- vehicle travel time, out-vehicle travel time, travel cost and comfort index were considered for development of mode choice models. It was observed that the results obtained from fuzzy logic results gave better prediction accuracy in comparison to the traditional MNL model. Thus it can be concluded that the fuzzy logic models were better able to capture and incorporate the human knowledge and reasoning into mode choice behaviour. Further, developed fuzzy logic models are applied to evaluate selected transport policies to demonstrate the suitability of the developed fuzzy logic mode choice models."
}

@misc{wang2018interp,
    title={Deep Neural Networks for Choice Analysis: Extracting Complete Economic Information for Interpretation},
    author={Shenhao Wang and Qingyi Wang and Jinhua Zhao},
    year={2018},
    eprint={1812.04528},
    archivePrefix={arXiv},
    primaryClass={econ.GN}
}

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6035992/
@article{zhang2018ann,
    author  = {Zhang, Z., Beck, M. W., Winkler, D. A., Huang, B., Sibanda, W., Goyal, H.},
    title   = {Opening the black box of neural networks: methods for interpreting neural network models in clinical applications.},
    journal = {Annals of translational medicine},
    volume  = {6},
    issue  = {11},
    number = {216},
    year    = {2018},
    doi = {https://doi.org/10.21037/atm.2018.05.32}
}

https://ideas.repec.org/p/ags/aaea15/205649.html
@techreport{bergtold2015nne,
    author={Bergtold, Jason S. and Ramsey, Steven M.},
    title={{Neural Network Estimators of Binary Choice Processes: Estimation, Marginal Effects and WTP}},
    year=2015,
    institution={Agricultural and Applied Economics Association},
    type={2015 AAEA \& WAEA Joint Annual Meeting, July 26-28, San Francisco, California},
    url={https://ideas.repec.org/p/ags/aaea15/205649.html},
    number={205649},
    abstract={Estimation of binary choice models typically require that the econometric model satisfy the utility maximization hypothesis. The most widely used models for this purpose are the binary logit and probit models. To satisfy the utility maximization hypothesis the logit and probit models must make a priori assumptions regarding the underlying functional form of a representative utility function. Such a theoretical restriction on a statistical model without considering the underlying probabilistic structure of the observed data can leave the postulated estimable model statistically misspecified. Feed-forward back-propagation artificial neural networks (FFBANN) provide a potentially powerful semi-nonparametric method to avoid misspecifications. This paper shows that a single-hidden layer FFBANN can be interpreted as a logistic regression with a flexible index function. An empirical application is conducted using FFBANNs to model a contingent valuation study and estimate marginal effects and willingness-to-pay. Results are used for comparison with more traditional methods such as the binary logit and probit models.},
    keywords={Environmental Economics and Policy; Research Methods/ Statistical Methods; Resource /Energy Economic},
    doi={10.22004/ag.econ.205649},
}

https://arxiv.org/pdf/1901.09839.pdf
@misc{ishhorowicz2019dnn,
    title={Interpreting Deep Neural Networks Through Variable Importance},
    author={Jonathan Ish-Horowicz and Dana Udwin and Seth Flaxman and Sarah Filippi and Lorin Crawford},
    year={2019},
    eprint={1901.09839},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

# https://arxiv.org/abs/1703.01365v2
@misc{sundararajan2017aadn,
    title={Axiomatic Attribution for Deep Networks},
    author={Mukund Sundararajan and Ankur Taly and Qiqi Yan},
    year={2017},
    eprint={1703.01365},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{beck2018nnt,
    author = {Marcus Beck},
    title = {NeuralNetTools: Visualization and Analysis Tools for Neural Networks},
    journal = {Journal of Statistical Software, Articles},
    volume = {85},
    number = {11},
    year = {2018},
    keywords = {neural networks; plotnet; sensitivity; variable importance; R},
    abstract = {Supervised neural networks have been applied as a machine learning technique to identify and predict emergent patterns among multiple variables. A common criticism of these methods is the inability to characterize relationships among variables from a fitted model. Although several techniques have been proposed to \"illuminate the black box\", they have not been made available in an open-source programming environment. This article describes the NeuralNetTools package that can be used for the interpretation of supervised neural network models created in R. Functions in the package can be used to visualize a model using a neural network interpretation diagram, evaluate variable importance by disaggregating the model weights, and perform a sensitivity analysis of the response variables to changes in the input variables. Methods are provided for objects from many of the common neural network packages in R, including caret, neuralnet, nnet, and RSNNS. The article provides a brief overview of the theoretical foundation of neural networks, a description of the package structure and functions, and an applied example to provide a context for model development with NeuralNetTools. Overall, the package provides a toolset for neural networks that complements existing quantitative techniques for data-intensive exploration.},
    issn = {1548-7660},
    pages = {1--20},
    doi = {10.18637/jss.v085.i11},
    url = {https://www.jstatsoft.org/v085/i11}
}

@article{wong2019resl,
    title={ResLogit: A residual neural network logit model},
    author={Wong, Melvin and Farooq, Bilal},
    journal={arXiv preprint arXiv:1912.10058},
    year={2019}
}





###################
# Simulation (MCMC)
###################

https://link.springer.com/article/10.2165/00003088-200140010-00002

https://ieeexplore.ieee.org/abstract/document/6147858

https://www.sciencedirect.com/science/article/abs/pii/S1755534517302002

https://books.google.fr/books?hl=fr&lr=&id=X01ZDwAAQBAJ&oi=fnd&pg=PP1&dq=introduction+simulation+data&ots=ebIGlrTXke&sig=EDeLzeyWdUa9PjIpkLUyJHnYj70&redir_esc=y#v=onepage&q=introduction%20simulation%20data&f=false

https://books.google.fr/books?hl=fr&lr=&id=ZXL6AQAAQBAJ&oi=fnd&pg=PP1&dq=introduction+simulation+data&ots=uPXnvX9EY6&sig=78cXLwdw-xOmowN779nxD7_o8e0&redir_esc=y#v=onepage&q=introduction%20simulation%20data&f=false

https://ieeexplore.ieee.org/abstract/document/5679166
https://orsociety.tandfonline.com/doi/abs/10.1057/jos.2012.20#.XqGLD8gzZcY

# https://eml.berkeley.edu/books/choice2.html (K. Train, 2009, "Discrete Choice Methods with Simulation" handbook)
@book{train2009dc,
  title={Discrete choice methods with simulation},
  author={Train, Kenneth E},
  year={2009},
  publisher={Cambridge university press}
}



####################
# Synthetic datasets 
####################

@article{albuquerque2011ds, 
    author={G. {Albuquerque} and T. {Lowe} and M. {Magnor}}, 
    journal={IEEE Transactions on Visualization and Computer Graphics}, 
    title={Synthetic Generation of High-Dimensional Datasets}, 
    year={2011}, 
    volume={17}, 
    number={12}, 
    pages={2317-2324},
    url={https://ieeexplore.ieee.org/abstract/document/6064998}
}

@article{garrow2010gs,
    author={Garrow, Laurie A.; Bodea, Tudor D.; Lee, Misuk},
    year={2010},
    title={Generation of synthetic datasets for discrete choice analysis},
    journal={Transportation},
    pages={183--202},
    volume={37},
    issue={2},
    abstract={Despite the widespread use of synthetic data in discrete choice analysis, little is known about how the methodology used to generate synthetic datasets influences the properties of parameter estimates and the validity of results based on these estimates. That is, there are two potential sources of biases when using synthetic discrete choice data: (1) bias due to the method used to generate the dataset; and, (2) bias due to parameter estimation. The primary objective of this study is to examine bias due to the underlying data generation method. This study compares three methods for generating synthetic datasets and uses design of experiments and analysis of variance methods to investigate the ability to recover estimates for “true” logsum parameters for nested logit models. The method that uses nested logit probabilities to generate the chosen alternative results in unbiased parameter estimates. The method that is based on Gumbel error component approximations reveals that while the error components themselves are unbiased, subtle empirical identification problems can arise when these error components are combined with synthetically generated utility functions. The method that is based on normal error component approximations reveals that all logsum coefficients are biased upwards; the bias dramatically increases for those nests that have a low choice frequency and is most pronounced for those nests with high correlations among alternatives. Based on the results of the analysis, several recommendations for the generation of synthetic datasets for discrete choice analyses are provided.},
    ibsn={1572-9435},
    url={https://doi.org/10.1007/s11116-009-9228-6},
    doi={10.1007/s11116-009-9228-6}
}

@inproceedings{vasilomanolakis2016ds, 
    author={E. {Vasilomanolakis} and C. G. {Cordero} and N. {Milanov} and M. {Mühlhäuser}}, 
    booktitle={NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium}, 
    title={Towards the creation of synthetic, yet realistic, intrusion detection datasets}, 
    year={2016}, 
    volume={}, 
    number={}, 
    pages={1209-1214},
    url={https://ieeexplore.ieee.org/abstract/document/7502989}
}

@article{gan2017sd,
    author = "Guojun Gan and Emiliano A. Valdez",
    title = "Valuation of large variable annuity portfolios: Monte Carlo simulation and synthetic datasets",
    journal = "Dependence Modeling",
    year = "2017",
    publisher = "De Gruyter",
    address = "Berlin, Boston",
    volume = "5",
    number = "1",
    pages = "354 - 374",
    url = "https://www.degruyter.com/view/journals/demo/5/1/article-p354.xml"
} 

@inproceedings{kar2019ms,
    author = {Kar, Amlan and Prakash, Aayush and Liu, Ming-Yu and Cameracci, Eric and Yuan, Justin and Rusiniak, Matt and Acuna, David and Torralba, Antonio and Fidler, Sanja},
    title = {Meta-Sim: Learning to Generate Synthetic Datasets},
    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
    month = {October},
    year = {2019},
    url = {http://openaccess.thecvf.com/content_ICCV_2019/html/Kar_Meta-Sim_Learning_to_Generate_Synthetic_Datasets_ICCV_2019_paper.html}
}

@article{charest2011dp, 
    title={How Can We Analyze Differentially-Private Synthetic Datasets?}, 
    volume={2}, 
    url={https://journalprivacyconfidentiality.org/index.php/jpc/article/view/589}, 
    DOI={10.29012/jpc.v2i2.589}, 
    abstractNote={Synthetic datasets generated within the multiple imputation framework are now commonly used by statistical agencies to protect the confidentiality of their respondents. More recently, researchers have also proposed techniques to generate synthetic datasets which offer the formal guarantee of differential privacy. While combining rules were derived for the first type of synthetic datasets, little has been said on the analysis of differentially-private synthetic datasets generated with multiple imputations. In this paper, we show that we can not use the usual combining rules to analyze synthetic datasets which have been generated to achieve differential privacy. We consider specifically the case of generating synthetic count data with the beta-binomial synthetizer, and illustrate our discussion with simulation results. We also propose as a simple alternative a Bayesian model which models explicitly the mechanism for synthetic data generation.}, 
    number={2}, 
    journal={Journal of Privacy and Confidentiality}, 
    author={Charest, Anne-Sophie}, 
    year={2011}, 
    month={Apr.}
} # Synthetic datasets and legislation (as was mentionned on 21/04)

@article{chiou2007sim,
    title = "Masking identification of discrete choice models under simulation methods",
    journal = "Journal of Econometrics",
    volume = "141",
    number = "2",
    pages = "683 - 703",
    year = "2007",
    issn = "0304-4076",
    doi = "https://doi.org/10.1016/j.jeconom.2006.10.012",
    url = "http://www.sciencedirect.com/science/article/pii/S0304407606002119",
    author = "Lesley Chiou and Joan L. Walker",
    keywords = "Simulation methods, Discrete choice, Identification",
    abstract = "We present examples based on actual and synthetic datasets to illustrate how simulation methods can mask identification problems in the estimation of discrete choice models such as mixed logit. Simulation methods approximate an integral (without a closed form) by taking draws from the underlying distribution of the random variable of integration. Our examples reveal how a low number of draws can generate estimates that appear identified, but in fact, are either not theoretically identified by the model or not empirically identified by the data. For the particular case of maximum simulated likelihood estimation, we investigate the underlying source of the problem by focusing on the shape of the simulated log-likelihood function under different conditions."
}

@article{drechsler2011sd_J,
    title = "An empirical evaluation of easily implemented, nonparametric methods for generating synthetic datasets",
    journal = "Computational Statistics & Data Analysis",
    volume = "55",
    number = "12",
    pages = "3232 - 3243",
    year = "2011",
    issn = "0167-9473",
    doi = "https://doi.org/10.1016/j.csda.2011.06.006",
    url = "http://www.sciencedirect.com/science/article/pii/S0167947311002076",
    author = "Jörg Drechsler and Jerome P. Reiter",
    keywords = "Census, Confidentiality, Disclosure, Imputation, Microdata, Synthetic",
    abstract = "When intense redaction is needed to protect the confidentiality of data subjects’ identities and sensitive attributes, statistical agencies can use synthetic data approaches. To create synthetic data, the agency replaces identifying or sensitive values with draws from statistical models estimated from the confidential data. Many agencies are reluctant to implement this idea because (i) the quality of the generated data depends strongly on the quality of the underlying models, and (ii) developing effective synthesis models can be a labor-intensive and difficult task. Recently, there have been suggestions that agencies use nonparametric methods from the machine learning literature to generate synthetic data. These methods can estimate non-linear relationships that might otherwise be missed and can be run with minimal tuning, thus considerably reducing burdens on the agency. Four synthesizers based on machine learning algorithms–classification and regression trees, bagging, random forests, and support vector machines–are evaluated in terms of their potential to preserve analytical validity while reducing disclosure risks. The evaluation is based on a repeated sampling simulation with a subset of the 2002 Uganda census public use sample data. The simulation suggests that synthesizers based on regression trees can result in synthetic datasets that provide reliable estimates and low disclosure risks, and that these synthesizers can be implemented easily by statistical agencies."
}





######################################
# Suggested articles from presentation
######################################

@article{bhat1995evm,
    type = {suggested},
    title = {A heteroscedastic extreme value model of intercity travel mode choice},
    author = {Bhat, Chandra R.},
    year = {1995},
    journal = {Transportation Research Part B: Methodological},
    volume = {29},
    number = {6},
    pages = {471-483},
    abstract = {Estimation of disaggregate mode choice models to estimate the ridership share on a proposed new (or improved) intercity travel service and to identify the modes from which existing intercity travelers will be diverted to the new or upgraded service constitutes a critical part of evaluating alternative travel service proposals to alleviate intercity travel congestion. This paper develops a new heteroscedastic extreme value model of intercity mode choice that overcomes the 'independence of irrelevant alternatives' (IIA) property of the commonly used multinomial logit model. The proposed model allows a more flexible cross-elasticity structure among alternatives than the nested logit model. It is also simple, intuitive and much less of a computational burden than the multinomial probit model. The paper discusses the non-IIA property of the heteroscedastic extreme value model and presents an efficient and accurate Gaussian quadrature technique to estimate the heteroscedastic model using the maximum likelihood method. The multinomial logit, alternative nested logit structures, and the heteroscedastic model are estimated to examine the impact of improved rail service on business travel in the Toronto-Montreal corridor. The nested logit structures are either inconsistent with utility maximization principles or are not significantly better than the multinomial logit model. The heteroscedastic extreme value model, however, is found to be superior to the multinomial logit model. The heteroscedastic model predicts smaller increases in rail shares and smaller decreases in non-rail shares than the multinomial logit in response to rail-service improvements. It also suggests a larger percentage decrease in air share and a smaller percentage decrease in auto share than the multinomial logit. Thus, the multinomial logit model is likely to provide overly optimistic projections of rail ridership and revenue, and of alleviation in inter-city travel congestion in general, and highway traffic congestion in particular. These findings point to the limitations of the multinomial logit and nested logit models in studying intercity mode choice behavior and to the usefulness of the heteroscedastic model proposed in this paper.},
    url = {https://EconPapers.repec.org/RePEc:eee:transb:v:29:y:1995:i:6:p:471-483}
}

@article{joly2019qcm,
    author={Bouscasse, Hélène and Joly, Iragaël and Peyhardi, Jean},
    title={{A new family of qualitative choice models: An application of reference models to travel mode choice}},
    journal={Transportation Research Part B: Methodological},
    year=2019,
    volume={121},
    number={C},
    pages={74-91},
    month={},
    keywords={Discrete choice model; Generalized linear model; Link function; Individual choice behavior},
    doi={10.1016/j.trb.2018.12.010},
    abstract={This paper considers the recently introduced family of reference models dedicated to non-ordered alternatives. The link function of reference models is that of the multinomial logit model (MNL) replacing the logistic cumulative distribution function (cdf) by other cdfs (e.g., Gumbel, Student). We determine all usual economic outputs (willingness-to-pay, elasticities,...). We also show that the IIA property generally does not hold for this family of models, because of their noninvariance to the alternative chosen as a reference. We estimate and compare five reference models to the MNL on a travel mode-choice survey: according to the chosen cdf, reference models lead to a better fit and retrieve consistent economic outputs estimations even when there is a high unobserved heterogeneity.},
    url={https://ideas.repec.org/a/eee/transb/v121y2019icp74-91.html}
}

@article{fiebig2010gmlm,
    title = {The Generalized Multinomial Logit Model: Accounting for Scale and Coefficient Heterogeneity},
    author = {Fiebig, Denzil and Keane, Michael and Louviere, Jordan and Wasi, Nada},
    year = {2010},
    journal = {Marketing Science},
    volume = {29},
    number = {3},
    pages = {393-421},
    abstract = {The mixed or heterogeneous multinomial logit (MIXL) model has become popular in a number of fields, especially marketing, health economics, and industrial organization. In most applications of the model, the vector of consumer utility weights on product attributes is assumed to have a multivariate normal (MVN) distribution in the population. Thus, some consumers care more about some attributes than others, and the IIA property of multinomial logit (MNL) is avoided (i.e., segments of consumers will tend to switch among the subset of brands that possess their most valued attributes). The MIXL model is also appealing because it is relatively easy to estimate. Recently, however, some researchers have argued that the MVN is a poor choice for modelling taste heterogeneity. They argue that much of the heterogeneity in attribute weights is accounted for by a pure scale effect (i.e., across consumers, all attribute weights are scaled up or down in tandem). This implies that choice behaviour is simply more random for some consumers than others (i.e., holding attribute coefficients fixed, the scale of their error term is greater). This leads to a “scale heterogeneity” MNL model (S-MNL). Here, we develop a generalized multinomial logit model (G-MNL) that nests S-MNL and MIXL. By estimating the S-MNL, MIXL, and G-MNL models on 10 data sets, we provide evidence on their relative performance. We find that models that account for scale heterogeneity (i.e., G-MNL or S-MNL) are preferred to MIXL by the Bayes and consistent Akaike information criteria in all 10 data sets. Accounting for scale heterogeneity enables one to account for “extreme” consumers who exhibit nearly lexicographic preferences, as well as consumers who exhibit very “random” behaviour (in a sense we formalize below).},
    keywords = {choice models; mixture models; consumer heterogeneity; choice experiments},
    url = {https://EconPapers.repec.org/RePEc:inm:ormksc:v:29:y:2010:i:3:p:393-421}
}

@article{mcfadden1974utd,
    title = "The measurement of urban travel demand",
    journal = "Journal of Public Economics",
    volume = "3",
    number = "4",
    pages = "303 - 328",
    year = "1974",
    issn = "0047-2727",
    doi = "https://doi.org/10.1016/0047-2727(74)90003-6",
    url = "http://www.sciencedirect.com/science/article/pii/0047272774900036",
    author = "Daniel McFadden"
}

@article{mcfadden2001ec,
    ISSN = {00028282},
    URL = {http://www.jstor.org/stable/2677869},
    author = {Daniel McFadden},
    journal = {The American Economic Review},
    number = {3},
    pages = {351--378},
    publisher = {American Economic Association},
    title = {Economic Choices},
    volume = {91},
    year = {2001}
}

@article{munizaga2005mlyp,
    author = {Marcela A. Munizaga and Ricardo Alvarez-Daziano},
    title ={Testing Mixed Logit and Probit Models by Simulation},
    journal = {Transportation Research Record},
    volume = {1921},
    number = {1},
    pages = {53-62},
    year = {2005},
    doi = {10.1177/0361198105192100107},
    URL = {https://doi.org/10.1177/0361198105192100107},
    eprint = {https://doi.org/10.1177/0361198105192100107},
    abstract = {Discrete choice models with error structures that are not independent and identically distributed have received enormous attention in the recent literature. A detailed synthetic study tests this type of model in a controlled case. With mixed logit and probit models as the study objects, calibration was implemented with the use of software available on the Internet. The controlled situation was built as a simulation laboratory, which generated databases with known parameters. The effects of various elements were analyzed: number of repetitions of the simulation, number of observations in the database, and how the use of Halton sequences improves the mixed logit calibration. The scale effects on the different models are also discussed. The results obtained in this specific context lead to some recommendations for future users of these powerful modeling tools. In particular, flexible structures require large sample sizes to calibrate the elements of the covariance matrix.}
}

@article{ODonoghue2018,
    Author = {O'Donoghue, Ted and Somerville, Jason},
    Title = {Modeling Risk Aversion in Economics},
    Journal = {Journal of Economic Perspectives},
    Volume = {32},
    Number = {2},
    Year = {2018},
    Month = {May},
    Pages = {91-114},
    DOI = {10.1257/jep.32.2.91},
    URL = {https://www.aeaweb.org/articles?id=10.1257/jep.32.2.91}
}








####################
# Technical articles
####################

@article{ognyanova2019r,
    title={Network visualization with R},
    author={Ognyanova, Katherine},
    journal={Network},
    volume={1},
    pages={T2},
    year={2019}
}

@article{athey2019rf,
    title={Generalized random forests},
    author={Athey, Susan and Tibshirani, Julie and Wager, Stefan and others},
    journal={The Annals of Statistics},
    volume={47},
    number={2},
    pages={1148--1178},
    year={2019},
    publisher={Institute of Mathematical Statistics}
}

@article{lewbel2019id,
    title={The identification zoo: Meanings of identification in econometrics},
    author={Lewbel, Arthur},
    journal={Journal of Economic Literature},
    volume={57},
    number={4},
    pages={835--903},
    year={2019}
}

@inproceedings{hancock2019quantum,
    title={Quantum probability: a new method for modelling travel choices},
    author={Hancock, Thomas O and Hess, Stephane and Choudhury, Charisma F},
    booktitle={The Transportation Research Board (TRB) 98th Annual Meeting},
    year={2019}
}

@article{vitetta2016quantum,
    title={A quantum utility model for route choice in transport systems},
    author={Vitetta, Antonino},
    journal={Travel Behaviour and Society},
    volume={3},
    pages={29--37},
    year={2016},
    publisher={Elsevier}
}

@article{yukalov2017quantum,
    title={Quantum probabilities as behavioral probabilities},
    author={Yukalov, Vyacheslav I and Sornette, Didier},
    journal={Entropy},
    volume={19},
    number={3},
    pages={112},
    year={2017},
    publisher={Multidisciplinary Digital Publishing Institute}
}

@article{chorus2010rrm,
    title={A new model of random regret minimization},
    author={Chorus, Caspar G},
    journal={European Journal of Transport and Infrastructure Research},
    volume={10},
    number={2},
    year={2010}
}

@article{boeri2014rrm,
    title={Regret minimisation and utility maximisation in a freight transport context},
    author={Boeri, Marco and Masiero, Lorenzo},
    journal={Transportmetrica A: Transport Science},
    volume={10},
    number={6},
    pages={548--560},
    year={2014},
    publisher={Taylor \& Francis}
}

@article{brito2013lda,
    title={Classification of cereal bars using near infrared spectroscopy and linear discriminant analysis},
    author={Brito, Anna Luiza Bizerra and Brito, Livia Rodrigues and Honorato, Fernanda Ara{\'u}jo and Pontes, M{\'a}rcio Jos{\'e} Coelho and Pontes, Liliana F{\'a}tima Bezerra Lira},
    journal={Food research international},
    volume={51},
    number={2},
    pages={924--928},
    year={2013},
    publisher={Elsevier}
}

@inproceedings{depalma2008dcm,
    title={Risk, uncertainty and discrete choice models},
    publisher={Springer Science + Business Media},
    year={2008}
}

@article{chorus2012rrm,
    author = { Caspar   Chorus },
    title = {Random Regret Minimization: An Overview of Model Properties and Empirical Evidence},
    journal = {Transport Reviews},
    volume = {32},
    number = {1},
    pages = {75-92},
    year  = {2012},
    publisher = {Routledge},
    doi = {10.1080/01441647.2011.609947},
    URL = {https://doi.org/10.1080/01441647.2011.609947},
    eprint = {https://doi.org/10.1080/01441647.2011.609947},
    abstract = { This paper presents an overview of model properties and empirical evidence related to the recently introduced discrete choice paradigm of random regret minimization (RRM). The RRM approach to discrete choice modelling provides an alternative to the conventional, linear-additive random utility maximization (RUM)-based approach which has dominated the field since its inception. Section of Transport and Logistics RRM models postulate that when choosing, decision-makers are concerned with avoiding the situation where one or more non-chosen alternatives perform better than a chosen one in terms of one or more attributes. From this central behavioural premise, semi-compensatory decision-making and choice set composition effects like the compromise effect emerge as RRM model features. Being as parsimonious as RUM's linear-additive multinomial logit model, RRM features logit choice probabilities and is easily estimable using conventional discrete choice software packages. This paper ties together the main insights and results from a number of recent studies that have explored RRM's model properties and empirically tested RRM-based models Delft University of Technology, based on a range of revealed and stated choice data sets. As such, the paper allows for an early assessment of RRM's potential and its limitations as a model of discrete (travel) choice behaviour. }
}

@article{bhat2012mnpm,
    title = "A new approach to specify and estimate non-normally mixed multinomial probit models",
    journal = "Transportation Research Part B: Methodological",
    volume = "46",
    number = "7",
    pages = "817 - 833",
    year = "2012",
    issn = "0191-2615",
    doi = "https://doi.org/10.1016/j.trb.2012.02.007",
    url = "http://www.sciencedirect.com/science/article/pii/S019126151200032X",
    author = "Chandra R. Bhat and Raghuprasad Sidharthan",
    keywords = "Multinomial probit, Mixed models, Maximum approximate composite marginal likelihood, Maximum simulated likelihood, Multivariate skew-normal distribution",
    abstract = "The current paper proposes the use of the multivariate skew-normal distribution function to accommodate non-normal mixing in cross-sectional and panel multinomial probit (MNP) models. The combination of skew-normal mixing and the MNP kernel lends itself nicely to estimation using Bhat’s (2011) maximum approximate composite marginal likelihood (MACML) approach. Simulation results for the cross-sectional case show that our proposed approach does well in recovering the underlying parameters, and also highlights the pitfalls of ignoring non-normality of the continuous mixing distribution when such non-normality is present. At the same time, the proposed model obviates the need to assume a pre-specified parametric distribution for the mixing, and allows the estimation of a very flexible, but still parsimonious, mixing distribution form."
}

@article{debock2010gam,
    title = "Ensemble classification based on generalized additive models",
    journal = "Computational Statistics & Data Analysis",
    volume = "54",
    number = "6",
    pages = "1535 - 1546",
    year = "2010",
    issn = "0167-9473",
    doi = "https://doi.org/10.1016/j.csda.2009.12.013",
    url = "http://www.sciencedirect.com/science/article/pii/S0167947309004654",
    author = "Koen W. [De Bock] and Kristof Coussement and Dirk [Van den Poel]",
    keywords = "Data mining, Classification, Ensemble learning, GAM, UCI",
    abstract = "Generalized additive models (GAMs) are a generalization of generalized linear models (GLMs) and constitute a powerful technique which has successfully proven its ability to capture nonlinear relationships between explanatory variables and a response variable in many domains. In this paper, GAMs are proposed as base classifiers for ensemble learning. Three alternative ensemble strategies for binary classification using GAMs as base classifiers are proposed: (i) GAMbag based on Bagging, (ii) GAMrsm based on the Random Subspace Method (RSM), and (iii) GAMens as a combination of both. In an experimental validation performed on 12 data sets from the UCI repository, the proposed algorithms are benchmarked to a single GAM and to decision tree based ensemble classifiers (i.e. RSM, Bagging, Random Forest, and the recently proposed Rotation Forest). From the results a number of conclusions can be drawn. Firstly, the use of an ensemble of GAMs instead of a single GAM always leads to improved prediction performance. Secondly, GAMrsm and GAMens perform comparably, while both versions outperform GAMbag. Finally, the value of using GAMs as base classifiers in an ensemble instead of standard decision trees is demonstrated. GAMbag demonstrates performance comparable to ordinary Bagging. Moreover, GAMrsm and GAMens outperform RSM and Bagging, while these two GAM ensemble variations perform comparably to Random Forest and Rotation Forest. Sensitivity analyses are included for the number of member classifiers in the ensemble, the number of variables included in a random feature subspace and the number of degrees of freedom for GAM spline estimation."
}

@article{yan2012nad,
    title={Using Non-Additive Measure for Optimization-Based Nonlinear Classification},
    journal={American Journal of Operations Research},
    volume={02},
    number={03},
    author={Nian Yan, Zhengxin Chen, Yong Shi, Zhenyuan Wang, Guimin Huang},
    doi={10.4236/ajor.2012.23044},
    year={2012},
    url={//www.scirp.org/journal/paperinformation.aspx?paperid=22432}
}

@article{hand2012perf,
    author = {Hand, David J.},
    title = {Assessing the Performance of Classification Methods},
    journal = {International Statistical Review},
    volume = {80},
    number = {3},
    pages = {400-414},
    keywords = {AUC, diagnosis, error rate, H measure, performance evaluation, ROC curve, sensitivity, signal detection, specificity, supervised classification},
    doi = {10.1111/j.1751-5823.2012.00183.x},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2012.00183.x},
    eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1751-5823.2012.00183.x},
    abstract = {Summary A large number of measures have been developed for evaluating the performance of classification rules. Some of these have been developed to meet the practical requirements of specific applications, but many others—which here we call “classification accuracy” criteria—represent different ways of balancing the different kinds of misclassification which may be made. This paper reviews classification accuracy criteria. However, the literature is now so large and diverse that a comprehensive list, covering all the measures and their variants, would probably be impossible. Instead, this paper embeds such measures in general framework, spanning the possibilities, and draws attention to relationships between them. Important points to note are, firstly, that different performance measures, by definition, measure different aspects of performance; secondly, that one should therefore carefully choose a measure to match the objectives of one's study; and, thirdly, that empirical comparisons between instruments measuring different aspects are of limited value.},
    year = {2012}
}

@inproceedings{bouchard2004tradeoff,
    title={The tradeoff between generative and discriminative classifiers},
    author={Bouchard, Guillaume and Triggs, Bill},
    year={2004}
}

@article{ferrara2017sem,
    title = "Semiparametric stochastic frontier models: A generalized additive model approach",
    journal = "European Journal of Operational Research",
    volume = "258",
    number = "2",
    pages = "761 - 777",
    year = "2017",
    issn = "0377-2217",
    doi = "https://doi.org/10.1016/j.ejor.2016.09.008",
    url = "http://www.sciencedirect.com/science/article/pii/S0377221716307445",
    author = "Giancarlo Ferrara and Francesco Vidoli",
    keywords = "Stochastic frontier, Semiparametric, Generalized additive model, Splines, Efficiency",
    abstract = "The choice of the functional form of the frontier into a stochastic frontier model is typically neglected in applications and canonical functions are usually considered. This paper introduces a semiparametric approach for stochastic frontier estimation that extends previous works based on pseudo-likelihood estimators allowing flexibility in model selection and capability of imposing monotonicity and concavity constraints. For these purposes the present work introduces a generalized additive framework that moreover permits to model the influence of contextual/environmental factors to the hypothesized production process by the relative extension given by generalized additive models for location, scale and shape. Through some Monte Carlo simulations and an application to European agricultural data the flexibility of the proposed framework in analyzing efficiency is illustrated."
}

@article{huang2000nop,
    title = "A nonparametric multiple choice method within the random utility framework",
    journal = "Journal of Econometrics",
    volume = "97",
    number = "2",
    pages = "207 - 225",
    year = "2000",
    issn = "0304-4076",
    doi = "https://doi.org/10.1016/S0304-4076(99)00072-X",
    url = "http://www.sciencedirect.com/science/article/pii/S030440769900072X",
    author = "J u-Chin Huang and Douglas W. Nychka",
    keywords = "Polychotomous choices, Cubic smoothing splines, Random utility model, Welfare measurement, Nonmarket valuation",
    abstract = "Many researchers use categorical data analysis to recover individual consumption preferences, but the standard discrete choice models require restrictive assumptions. To improve the flexibility of discrete choice data analysis, we propose a nonparametric multiple choice model that applies the penalized likelihood method within the random utility framework. We show that the deterministic component of the random utility function in the model is a cubic smoothing spline function. The method subsumes the conventional conditional logit model (McFadden, 1973, in: Zarembka, P., (Ed.), Frontiers in Econometrics) as a special case. In this paper, we present the model, describe the estimator, provide the computational algorithm of the model, and demonstrate the model by applying it to nonmarket valuation of recreation sites."
}

@article{zhang2018gam,
    title = "Efficient estimation and computation for the generalised additive models with unknown link function",
    journal = "Journal of Econometrics",
    volume = "202",
    number = "2",
    pages = "230 - 244",
    year = "2018",
    issn = "0304-4076",
    doi = "https://doi.org/10.1016/j.jeconom.2017.11.001",
    url = "http://www.sciencedirect.com/science/article/pii/S0304407617302208",
    author = "Huazhen Lin and Lixian Pan and Shaogao Lv and Wenyang Zhang",
    keywords = "Generalised additive model, Local linear smoothing, Quasi-likelihood, Asymptotical properties, Semiparametric efficiency",
    abstract = "The generalised additive models (GAM) are widely used in data analysis. In the application of the GAM, the link function involved is usually assumed to be a commonly used one without justification. Motivated by a real data example with binary response where the commonly used link function does not work, we propose a generalised additive models with unknown link function (GAMUL) for various types of data, including binary, continuous and ordinal. The proposed estimators are proved to be consistent and asymptotically normal. Semiparametric efficiency of the estimators is demonstrated in terms of their linear functionals. In addition, an iterative algorithm, where all estimators can be expressed explicitly as a linear function of Y, is proposed to overcome the computational hurdle for the GAM type model. Extensive simulation studies conducted in this paper show the proposed estimation procedure works very well. The proposed GAMUL are finally used to analyze a real dataset about loan repayment in China, which leads to some interesting findings."
}

@article{si2019inf,
    title={INFERENCE ON HIGH DIMENSIONAL DISCRETE CHOICE MODEL},
    author={Si, Danilo R and Lansangan, Joseph Ryan G and Barrios, Erniel B},
    year={2019}
}

@article{domshlak2011pref,
    title = "Preferences in AI: An overview",
    journal = "Artificial Intelligence",
    volume = "175",
    number = "7",
    pages = "1037 - 1052",
    year = "2011",
    note = "Representing, Processing, and Learning Preferences: Theoretical and Practical Challenges",
    issn = "0004-3702",
    doi = "https://doi.org/10.1016/j.artint.2011.03.004",
    url = "http://www.sciencedirect.com/science/article/pii/S000437021100049X",
    author = "Carmel Domshlak and Eyke Hüllermeier and Souhila Kaci and Henri Prade",
    keywords = "Preference, Graphical representation, Logical representation, Aggregation functions, Preference queries, Preference learning",
    abstract = "This editorial of the special issue “Representing, Processing, and Learning Preferences: Theoretical and Practical Challenges” surveys past and ongoing research on preferences in AI, including references and pointers to the literature. It covers approaches to representation, reasoning and learning of preferences. Methods in AI are contrasted with those in related areas, such as operations research and databases. Finally, we also give a brief introduction to the contents of the special issue."
}

https://www.sciencedirect.com/science/article/abs/pii/S0191261514001167

https://www.sciencedirect.com/science/article/abs/pii/S0965856415000166





